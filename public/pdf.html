<!DOCTYPE html><html><head>
    <!--
    <meta charset="utf-8" />
    <meta name="description" content="${description}">
    <meta name="keywords" content="${keywords}">
    <title>${pageTitle}</title>
    <link rel="canonical" href="${canonicalURL}">
    <link rel="version-history" href="${publication.repositoryUrl}">
    -->
    <link rel="stylesheet" href="pdf.css">
  </head>
  <body>
  

<svg style="display: none">
      <symbol id="left-arrow-icon" viewBox="0 0 18 32">
        <path d="M23.1,11.1L21,9l-9,9l9,9l2.1-2.1L16.2,18L23.1,11.1z"></path>
      </symbol>
      <symbol id="right-arrow-icon" viewBox="0 0 18 32">
        <path d="M12.9,11.1L15,9l9,9l-9,9l-2.1-2.1l6.9-6.9L12.9,11.1z"></path>
      </symbol>
      <symbol id="search-icon" viewBox="0 0 32 32">
        <path d="M18.6,16.4h-1.2L17,16c1.5-1.7,2.3-3.9,2.3-6.3C19.3,4.3,15,0,9.7,0S0,4.3,0,9.7s4.3,9.7,9.7,9.7c2.4,0,4.6-0.9,6.3-2.3
      l0.4,0.4v1.2l7.4,7.4l2.2-2.2L18.6,16.4z M9.7,16.4C6,16.4,3,13.4,3,9.7S6,3,9.7,3s6.7,3,6.7,6.7S13.4,16.4,9.7,16.4z"></path>
      </symbol>
      <symbol id="nav-icon" viewBox="0 0 32 32">
        <path d="M0,6.7h24.9V3.1H0V6.7z M0,13.8h24.9v-3.6H0V13.8z M0,20.9h24.9v-3.6H0V20.9z M28.4,20.9H32v-3.6h-3.6V20.9z M28.4,3.1v3.6
      H32V3.1H28.4z M28.4,13.8H32v-3.6h-3.6V13.8z"></path>
      </symbol>
      <symbol id="arrow-forward-icon" viewBox="0 0 32 32">
        <path d="M16,5.3l-1.9,1.9l7.4,7.5H5.3v2.7h16.2l-7.4,7.5l1.9,1.9L26.7,16L16,5.3z"></path>
      </symbol>
      <symbol id="home-icon" viewBox="0 0 32 32">
        <path d="M11,18V6l-8.5,6L11,18z M11.5,12l8.5,6V6L11.5,12z"></path>
      </symbol>
      <symbol id="start-icon" viewBox="0 0 32 32">
        <path d="M8,5v14l11-7L8,5z"></path>
      </symbol>
      <symbol id="down-arrow-icon" viewBox="0 0 32 32">
        <path d="M16.6,8.6L12,13.2L7.4,8.6L6,10l6,6l6-6L16.6,8.6z"></path>
      </symbol>
      <symbol id="link-icon" viewBox="0 0 20 20">
        <path d="M3.3,16.7c-1.4-1.4-1.4-3.7,0-5.1l3.3-3.3L5,6.7L1.7,10c-2.3,2.3-2.3,6,0,8.3s6,2.3,8.3,0l3.3-3.3l-1.6-1.6l-3.3,3.3
          C7,18.1,4.7,18.1,3.3,16.7z M7.5,14.1l6.6-6.6l-1.7-1.7l-6.6,6.6L7.5,14.1z M10,1.7L6.7,5l1.6,1.6l3.3-3.3c1.4-1.4,3.7-1.4,5.1,0
          s1.4,3.7,0,5.1l-3.3,3.3l1.6,1.6l3.3-3.3c2.3-2.3,2.3-6,0-8.3S12.3-0.6,10,1.7z"></path>
      </symbol>
      <symbol id="close-icon" viewBox="0 0 48 48">
        <path d="M38 12.83L35.17 10 24 21.17 12.83 10 10 12.83 21.17 24 10 35.17 12.83 38 24 26.83 35.17 38 38 35.17 26.83 24z"></path>
      </symbol>
      <symbol id="download-icon" viewBox="0 0 32 32">
        <path d="M28.4,16v12.4H3.6V16H0v12.4c0,2,1.6,3.6,3.6,3.6h24.9c2,0,3.6-1.6,3.6-3.6V16H28.4z M17.8,17.2l4.6-4.6l2.5,2.5L16,24
          l-8.9-8.9l2.5-2.5l4.6,4.6V0h3.6V17.2z"></path>
      </symbol>
      <symbol id="plus-icon" viewBox="0 0 16 16">
        <path d="M26 0C11.664 0 0 11.663 0 26s11.664 26 26 26 26-11.663 26-26S40.336 0 26 0zm0 50C12.767 50 2 39.233 2 26S12.767 2 26 2s24 10.767 24 24-10.767 24-24 24z"></path>
        <path d="M38.5 25H27V14c0-.553-.448-1-1-1s-1 .447-1 1v11H13.5c-.552 0-1 .447-1 1s.448 1 1 1H25v12c0 .553.448 1 1 1s1-.447 1-1V27h11.5c.552 0 1-.447 1-1s-.448-1-1-1z"></path>
      </symbol>
      <symbol id="fullscreen-icon" viewBox="0 0 24 24">
        <path d="M0 0h24v24H0z" fill="none"></path>
        <path d="M7 14H5v5h5v-2H7v-3zm-2-4h2V7h3V5H5v5zm12 7h-3v2h5v-5h-2v3zM14 5v2h3v3h2V5h-5z"></path>
      </symbol>
      <symbol id="add-circle-icon" viewBox="0 0 20 20">
        <path d="M9.25 14h1.5v-3.25H14v-1.5h-3.25V6h-1.5v3.25H6v1.5h3.25Zm.75 4q-1.646 0-3.104-.625-1.458-.625-2.552-1.719t-1.719-2.552Q2 11.646 2 10q0-1.667.625-3.115.625-1.447 1.719-2.541Q5.438 3.25 6.896 2.625T10 2q1.667 0 3.115.625 1.447.625 2.541 1.719 1.094 1.094 1.719 2.541Q18 8.333 18 10q0 1.646-.625 3.104-.625 1.458-1.719 2.552t-2.541 1.719Q11.667 18 10 18Zm0-1.5q2.708 0 4.604-1.896T16.5 10q0-2.708-1.896-4.604T10 3.5q-2.708 0-4.604 1.896T3.5 10q0 2.708 1.896 4.604T10 16.5Zm0-6.5Z"></path>
      </symbol>
      <symbol id="rotation-icon" viewBox="0 0 24 24">
        <path d="M8.76918 19.1836L7.77593 18.1904L9.67785 16.2779C7.68107 16.0073 6.01922 15.4801 4.6923 14.6961C3.36537 13.9121 2.7019 13.0201 2.7019 12.0202C2.7019 10.8314 3.60117 9.80777 5.3997 8.9493C7.19822 8.09082 9.39805 7.66158 11.9992 7.66158C14.6003 7.66158 16.8004 8.09082 18.5995 8.9493C20.3985 9.80777 21.298 10.8314 21.298 12.0202C21.298 12.8584 20.8103 13.633 19.835 14.344C18.8597 15.055 17.5679 15.5936 15.9596 15.9596V14.5298C17.2211 14.1965 18.1931 13.7907 18.8754 13.3125C19.5578 12.8343 19.899 12.4035 19.899 12.0202C19.899 11.4676 19.197 10.8362 17.7929 10.126C16.3888 9.4157 14.4582 9.06057 12.001 9.06057C9.5439 9.06057 7.61293 9.4157 6.20813 10.126C4.80331 10.8362 4.1009 11.4676 4.1009 12.0202C4.1009 12.4587 4.59338 12.9806 5.57833 13.5861C6.56328 14.1915 7.89133 14.6154 9.56248 14.8577L7.77593 13.0711L8.76918 12.0779L12.322 15.6308L8.76918 19.1836Z"></path>
      </symbol>
    </svg><svg style="display: none" data-outputs-exclude="epub,pdf">
      <symbol id="by" viewBox="0 0 60 60" xmlns="http://www.w3.org/2000/svg">
        <path d="M29.9 0C38.3 0 45.4 2.9 51.2 8.7C57 14.5 59.9 21.6 59.9 30C59.9 38.4 57 45.4 51.3 51.1C45.2 57.1 38.1 60 29.8 60C21.7 60 14.7 57.1 8.7 51.2C2.9 45.3 0 38.2 0 30C0 21.8 2.9 14.7 8.8 8.7C14.6 2.9 21.7 0 29.9 0ZM30.1 5.4C23.3 5.4 17.5 7.8 12.8 12.6C7.9 17.6 5.5 23.4 5.5 30C5.5 36.6 7.9 42.4 12.8 47.2C17.7 52.1 23.4 54.5 30.2 54.5C36.9 54.5 42.7 52.1 47.7 47.2C52.4 42.7 54.8 36.9 54.8 30C54.8 23.2 52.4 17.4 47.6 12.6C42.6 7.8 36.8 5.4 30.1 5.4ZM38.1 22.6V34.9H34.7V49.5H25.4V34.8H22V22.6C22 22.1 22.2 21.6 22.6 21.2C23 20.8 23.4 20.6 24 20.6H36.3C36.8 20.6 37.2 20.8 37.6 21.2C37.9 21.6 38.1 22 38.1 22.6ZM25.8 14.8C25.8 12 27.2 10.6 30 10.6C32.8 10.6 34.2 12 34.2 14.8C34.2 17.6 32.8 19 30 19C27.2 19 25.8 17.6 25.8 14.8Z" fill="currentColor"></path>
      </symbol>
      <symbol id="cc" viewBox="0 0 60 60" xmlns="http://www.w3.org/2000/svg">
        <path d="M29.9 0C38.3 0 45.4 2.90484 51.3 8.81469C54.1 11.6194 56.3 14.8247 57.7 18.5309C59.3 22.1369 60 25.9432 60 30.0501C60 34.1569 59.3 38.0634 57.8 41.5693C56.4 45.1753 54.2 48.3806 51.4 51.0851C48.5 53.99 45.2 56.1937 41.4 57.6962C37.7 59.1987 33.8 60 29.9 60C26 60 22.1 59.1987 18.5 57.6962C14.9 56.1937 11.6 53.99 8.7 51.0851C5.8 48.1803 3.6 44.975 2.1 41.3689C0.6 37.7629 0 34.0568 0 30.0501C0 26.0434 0.8 22.2371 2.3 18.6311C3.8 15.025 6 11.6194 8.9 8.71452C14.6 2.90484 21.6 0 29.9 0ZM30.1 5.40901C23.2 5.40901 17.5 7.81302 12.8 12.621C10.4 15.025 8.6 17.7295 7.4 20.7346C6.1 23.7396 5.5 26.8447 5.5 30.0501C5.5 33.2554 6.1 36.3606 7.4 39.3656C8.7 42.3706 10.5 44.975 12.8 47.379C15.2 49.6828 17.8 51.4858 20.8 52.788C23.8 53.99 26.9 54.591 30.1 54.591C33.3 54.591 36.4 53.99 39.4 52.6878C42.4 51.3856 45.1 49.5826 47.6 47.2788C52.3 42.6711 54.6 36.9616 54.6 30.0501C54.6 26.7446 54 23.5392 52.8 20.6344C51.6 17.6294 49.8 15.025 47.5 12.7212C42.6 7.81302 36.8 5.40901 30.1 5.40901ZM29.7 25.0417L25.7 27.1452C25.3 26.2437 24.7 25.6427 24.1 25.2421C23.5 24.8414 22.9 24.7412 22.4 24.7412C19.7 24.7412 18.4 26.5442 18.4 30.0501C18.4 31.6528 18.7 32.9549 19.4 33.9566C20.1 34.9583 21.1 35.3589 22.4 35.3589C24.2 35.3589 25.4 34.4574 26.1 32.7546L29.8 34.6578C29 36.1603 27.9 37.2621 26.5 38.1636C25.1 38.9649 23.6 39.4658 21.9 39.4658C19.2 39.4658 17.1 38.6644 15.4 36.9616C13.8 35.3589 12.9 33.0551 12.9 30.0501C12.9 27.1452 13.7 24.9416 15.4 23.2387C17.1 21.5359 19.2 20.7346 21.7 20.7346C25.4 20.7346 28.1 22.1369 29.7 25.0417ZM47 25.0417L43 27.1452C42.6 26.2437 42 25.6427 41.4 25.2421C40.8 24.8414 40.2 24.7412 39.6 24.7412C36.9 24.7412 35.6 26.5442 35.6 30.0501C35.6 31.6528 35.9 32.9549 36.6 33.9566C37.3 34.9583 38.3 35.3589 39.6 35.3589C41.3 35.3589 42.6 34.4574 43.3 32.7546L47.1 34.6578C46.3 36.1603 45.2 37.2621 43.8 38.1636C42.4 38.9649 40.9 39.4658 39.2 39.4658C36.5 39.4658 34.3 38.6644 32.7 36.9616C31.1 35.3589 30.3 33.0551 30.3 30.0501C30.3 27.1452 31.1 24.9416 32.8 23.2387C34.5 21.5359 36.6 20.7346 39.1 20.7346C42.8 20.7346 45.4 22.1369 47 25.0417Z" fill="currentColor"></path>
      </symbol>
      <symbol id="nc" viewBox="0 0 60 60" xmlns="http://www.w3.org/2000/svg">
        <path d="M30 0C38.4 0 45.5 2.9 51.3 8.7C57.1 14.5 60 21.6 60 30C60 38.4 57.1 45.4 51.4 51.1C45.3 57.1 38.2 60 29.9 60C21.8 60 14.7 57 8.80001 51.1C2.90001 45.2 0 38.2 0 30C0 21.8 2.90001 14.7 8.80001 8.7C14.7 2.9 21.8 0 30 0ZM6.90001 21.9C6.00001 24.4 5.60001 27.1 5.60001 30C5.60001 36.6 8.00001 42.4 12.9 47.3C17.8 52.1 23.6 54.5 30.3 54.5C37.1 54.5 42.9 52.1 47.8 47.2C49.6 45.5 50.9 43.8 51.9 41.9L40.6 36.9C40.2 38.8 39.3 40.3 37.7 41.5C36.2 42.7 34.4 43.4 32.3 43.6V48.2H28.8V43.6C25.5 43.6 22.4 42.4 19.7 40L23.8 35.8C25.8 37.6 28 38.5 30.5 38.5C31.5 38.5 32.4 38.3 33.2 37.8C33.9 37.3 34.3 36.6 34.3 35.5C34.3 34.7 34 34.1 33.5 33.7L30.6 32.5L27.1 30.9L22.3 28.8L6.90001 21.9ZM30.2 5.4C23.4 5.4 17.6 7.8 12.9 12.6C11.7 13.8 10.6 15.1 9.60001 16.6L21.1 21.7C21.6 20.1 22.5 18.9 23.9 17.9C25.3 17 26.9 16.4 28.8 16.3V11.7H32.3V16.3C35.1 16.4 37.5 17.4 39.8 19.1L35.9 23.1C34.2 21.9 32.5 21.3 30.8 21.3C29.9 21.3 29 21.5 28.3 21.8C27.6 22.2 27.2 22.8 27.2 23.6C27.2 23.9 27.3 24.1 27.5 24.4L31.3 26.1L33.9 27.3L38.7 29.4L54.1 36.3C54.6 34.2 54.9 32.1 54.9 29.9C54.9 23 52.5 17.2 47.7 12.5C42.8 7.8 37 5.4 30.2 5.4Z" fill="currentColor"></path>
      </symbol>
      <symbol id="nd" viewBox="0 0 60 60" xmlns="http://www.w3.org/2000/svg">
        <path d="M30 0C38.4 0 45.5 2.9 51.3 8.7C57.1 14.5 60 21.6 60 30C60 38.4 57.1 45.4 51.4 51.1C45.4 57 38.2 60 29.9 60C21.8 60 14.8 57.1 8.8 51.2C2.90001 45.3 0 38.3 0 30C0 21.8 2.90001 14.7 8.8 8.7C14.8 2.9 21.8 0 30 0ZM30.2 5.4C23.4 5.4 17.6 7.8 12.9 12.6C8.00001 17.6 5.60001 23.4 5.60001 30C5.60001 36.7 8.00001 42.4 12.9 47.3C17.8 52.2 23.5 54.6 30.3 54.6C37 54.6 42.8 52.2 47.8 47.3C52.5 42.7 54.9 37 54.9 30.1C54.9 23.2 52.5 17.5 47.7 12.7C42.8 7.8 37 5.4 30.2 5.4ZM41.5 22.9V28H19.7V22.9H41.5ZM41.5 32.6V37.7H19.7V32.6H41.5Z" fill="currentColor"></path>
      </symbol>
      <symbol id="sa" viewBox="0 0 60 60" xmlns="http://www.w3.org/2000/svg">
        <path d="M30 0C38.4 0 45.5 2.9 51.3 8.7C57.1 14.5 60 21.6 60 30C60 38.4 57.1 45.4 51.4 51.1C45.4 57 38.2 60 29.9 60C21.8 60 14.8 57.1 8.8 51.2C2.9 45.3 0 38.3 0 30C0 21.8 2.9 14.7 8.8 8.7C14.8 2.9 21.8 0 30 0ZM30.2 5.4C23.4 5.4 17.6 7.8 12.9 12.6C8.00001 17.6 5.60001 23.4 5.60001 30C5.60001 36.7 8.00001 42.4 12.9 47.2C17.8 52.1 23.5 54.5 30.3 54.5C37 54.5 42.8 52.1 47.8 47.2C52.5 42.6 54.9 36.9 54.9 30C54.9 23.1 52.5 17.4 47.7 12.6C42.8 7.8 37 5.4 30.2 5.4ZM16.8 25.8C17.4 22.1 18.9 19.3 21.2 17.3C23.6 15.3 26.5 14.3 29.9 14.3C34.6 14.3 38.4 15.8 41.1 18.9C43.9 21.9 45.3 25.8 45.3 30.6C45.3 35.2 43.9 39 41 42.1C38.1 45.2 34.4 46.7 29.7 46.7C26.3 46.7 23.4 45.7 20.9 43.6C18.4 41.6 17 38.7 16.5 34.9H24.1C24.3 38.5 26.5 40.4 30.7 40.4C32.8 40.4 34.5 39.5 35.8 37.7C37.1 35.9 37.7 33.4 37.7 30.4C37.7 27.2 37.1 24.8 35.9 23.1C34.7 21.4 33 20.6 30.8 20.6C26.8 20.6 24.5 22.4 24 25.9H26.2L20.3 31.8L14.4 25.9L16.8 25.8Z" fill="currentColor"></path>
      </symbol>
      <symbol id="zero" viewBox="0 0 60 60" xmlns="http://www.w3.org/2000/svg">
        <path d="M30 12.7C20.1 12.7 17.6 22 17.6 30C17.6 37.9 20.1 47.3 30 47.3C39.9 47.3 42.4 38 42.4 30C42.4 22.1 39.9 12.7 30 12.7ZM30 19.2C30.4 19.2 30.8 19.3 31.1 19.3C31.8 19.9 32.2 20.8 31.5 21.9L24.9 34C24.7 32.5 24.7 31 24.7 29.8C24.7 26.5 24.9 19.2 30 19.2ZM34.9 24.8C35.2 26.7 35.3 28.6 35.3 30C35.3 33.5 35.1 40.8 30 40.8C29.6 40.8 29.2 40.8 28.9 40.7C28.8 40.7 28.8 40.7 28.7 40.6C28.6 40.6 28.5 40.5 28.4 40.5C27.3 40 26.6 39.1 27.6 37.6L34.9 24.8Z" fill="currentColor"></path>
        <path d="M29.9 0C21.6 0 14.6 2.9 8.8 8.7C5.9 11.6 3.7 14.9 2.2 18.6C0.699997 22.2 0 26 0 30C0 34 0.699997 37.8 2.2 41.4C3.7 45 5.9 48.3 8.7 51.1C11.6 54 14.8 56.2 18.4 57.7C22.2 59.3 26 60 29.9 60C33.9 60 37.7 59.2 41.4 57.7C45.1 56.2 48.4 54 51.4 51.1C54.2 48.4 56.4 45.2 57.8 41.6C59.3 38 60 34.1 60 30C60 25.9 59.3 22.1 57.8 18.5C56.3 14.9 54.2 11.6 51.4 8.8C45.5 2.9 38.3 0 29.9 0ZM30.1 5.4C36.9 5.4 42.7 7.8 47.5 12.6C49.8 14.9 51.6 17.6 52.8 20.5C54 23.5 54.6 26.6 54.6 29.9C54.6 36.8 52.2 42.5 47.6 47.1C45.2 49.5 42.4 51.3 39.4 52.5C36.4 53.8 33.3 54.4 30.1 54.4C26.8 54.4 23.7 53.8 20.8 52.6C17.8 51.3 15.2 49.6 12.8 47.2C10.4 44.8 8.6 42.2 7.3 39.2C6.1 36.2 5.4 33.1 5.4 29.9C5.4 26.6 6 23.5 7.3 20.6C8.6 17.6 10.4 14.9 12.8 12.5C17.4 7.8 23.2 5.4 30.1 5.4Z" fill="currentColor"></path>
      </symbol>
    </svg><section class="quire-page frontmatter quire-cover" data-footer-page-title="" id="index">
          <section class="quire-cover__hero hero is-fullheight">
            <div class="quire-cover__overlay" style="background-image: url(_assets/images/install/SP-chung22.jpg);">
            <div class="quire-cover__hero-body hero-body">
              <div class="container is-fluid">
                <h1 class="title" id="page-header-index">
                  The Imitation Game

                  <span class="visually-hidden">: </span>
                  <span class="subtitle">Visual Culture in the Age of Artificial Intelligence</span>
                </h1>
                <p class="reading-line"></p>
                <div class="contributor">
                  <span class="visually-hidden">Contributors:&nbsp;</span>

                  <em>Glenn Entis and Bruce Grenville</em>
                </div>
              </div>
            </div>
          </div></section>

          <section class="quire-cover__more">
            <div class="quire-cover__more-body hero-more next-page">
              <a href="#contents">
                
                
              </a>
            </div>
          </section>
        </section><section class="quire-page frontmatter half-title-page" data-footer-page-title="" id="pdf-epub-half-title">
          <section class="half-title">
            <p>The Imitation Game</p>
          </section>
        </section><section class="quire-page frontmatter title-page" data-footer-page-title="" id="pdf-epub-title">
          <section class="title-block">
            <h1 class="title">
              The Imitation Game: Visual Culture in the Age of Artificial
              Intelligence
            </h1>
            <p class="contributor">Glenn Entis and Bruce Grenville</p>
          </section>
          <section class="publisher-block">
            <p class="publisher">Vancouver Art Gallery, Vancouver</p>
          </section>
        </section><section class="quire-page frontmatter backmatter" data-footer-page-title="" id="pdf-epub-copyright">
          <div class="quire-copyright">
            <img src="\_assets\images\vaglogo.png" class="copyright__publisher-logo" alt="Vancouver Art Gallery">
            <p>© 2023 Vancouver Art Gallery</p>
            <a class="quire-copyright__icon__link" href="#https-creativecommons-org-licenses-by-4-0" rel="license" target="_blank">
              <svg class="quire-copyright__icon">
                <use xlink:href="#cc"></use>
              </svg>
              <svg class="quire-copyright__icon">
                <use xlink:href="#by"></use>
              </svg>
            </a>
            <div class="is-screen-only">
              This work is licensed under a
              <a rel="license" href="#https-creativecommons-org-licenses-by-4-0" target="_blank">Creative Commons Attribution 4.0 International License</a>.
              <span class="is-print-only">
                To view a copy of this license visit
                https://creativecommons.org/licenses/by/4.0/.
              </span>
            </div>
            <div class="is-print-only">
              This work is licensed under a
              <a rel="license" href="#https-creativecommons-org-licenses-by-4-0" target="_blank">Creative Commons Attribution 4.0 International License</a>.
              <span class="is-print-only">
                To view a copy of this license visit
                https://creativecommons.org/licenses/by/4.0/.
              </span>
            </div>
          </div>
          <p>ISBN: 978-1-927656-65-5</p>
        </section><section class="quire-page frontmatter quire-contents" data-footer-page-title="Contents" id="contents">
          <section class="quire-page__header hero">
            <div class="hero-body">
              <h1 class="quire-page__header__title" id="contents">Contents</h1>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container">
              <div class="quire-contents-list list">
                
                
                <nav class="table-of-contents menu-list" data-outputs-include="pdf">
                  <ol class="table-of-contents-list">
                    <li class="level-0 page-item">
                      <a href="#foreword">Director’s Foreword</a>
                    </li>
                    <li class="level-0 page-item">
                      <a href="#introduction">Introduction</a>
                    </li>
                    <li class="level-0 section-item">
                      <a href="#20-objects">20 Objects of Wonder</a>

                      <ol class="table-of-contents-list">
                        <li class="level-1 page-item">
                          <a href="#20-objects-01-wieners-moth">1. Norbert Wiener’s Moth</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-02-imitation-game">2. Alan Turing – The Imitation Game</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-03-space-odyssey">3. 2001: A Space Odyssey</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-04-cybernetic-serendipity">4. Cybernetic Serendipity</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-05-project-cybersyn">5. Project Cybersyn</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-06-simcity">6. SimCity</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-07-boids-autonomous-agents">7. Boids and Autonomous Agents</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-08-muriel-cooper">8. Muriel Cooper – Information Landscapes</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-09-bina48">9. Bina48</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-10-imagenet">10. ImageNet</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-11-alphago">11. AlphaGo – Game 2 – Move 37</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-12-gan">12. GAN</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-13-barrat-balenciaga">13. Robbie Barrat x Balenciaga</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-14-zaha-hadid-architects">14. Zaha Hadid Architects – Morpehus Hotel</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-15-algorithmic-justice-league">15. Algorithmic Justice League</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-16-ai-animation">16. AI in Animation</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-17-neri-oxman">17. Neri Oxman – Synthetic Apiary</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-18-smartphone">18. The Smartphone</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-19-metahuman-creator">19. MetaHuman Creator</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#20-objects-20-emotion-recognition">20. Emotion Recognition</a>
                        </li>
                      </ol>
                    </li>
                    <li class="level-0 section-item">
                      <a href="#special-projects-pause">Special Projects: Pause</a>

                      <ol class="table-of-contents-list">
                        <li class="level-1 page-item">
                          <a href="#special-projects-pause-sp-creepers">Creepers</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#special-projects-pause-sp-airegan">*airegan</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#special-projects-pause-sp-frid-jimenez">Amber Frid-Jimenez</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#special-projects-pause-sp-bjarke-ingels">Bjarke Ingels Group Vancouver House</a>
                        </li>
                      </ol>
                    </li>
                    <li class="level-0 section-item">
                      <a href="#special-projects-artists-projects">Special Projects: Artist Projects</a>

                      <ol class="table-of-contents-list">
                        <li class="level-1 page-item">
                          <a href="#special-projects-artists-projects-sp-pennefather">Patrick Pennefather</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#special-projects-artists-projects-sp-chung">Sougwen Chung</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#special-projects-artists-projects-sp-eaton">Scott Eaton</a>
                        </li>
                        <li class="level-1 page-item">
                          <a href="#special-projects-artists-projects-sp-zombie">The Zombie Formalist</a>
                        </li>
                      </ol>
                    </li>
                    <li class="level-0 page-item">
                      <a href="#ai-glossary">AI Glossary</a>
                    </li>
                    <li class="level-0 page-item">
                      <a href="#contributors">Contributors</a>
                    </li>
                    <li class="level-0 page-item">
                      <a href="#colophon">Colophon</a>
                    </li>
                  </ol>
                </nav>
                <div class="content"></div>
              </div>
              
            </div>
          </section>
        </section><section class="quire-page page-one" data-footer-page-title="Director’s Foreword" id="foreword">
          <section class="quire-page__header hero">
            <div class="hero-body">
              <h1 class="quire-page__header__title" id="director-s-foreword">
                Director’s Foreword
              </h1>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container">
              <div class="content"></div>
              
            </div>
          </section>
        </section><section class="quire-page" data-footer-page-title="Introduction" id="introduction">
          <section class="quire-page__header hero">
            <div class="hero-body">
              <h1 class="quire-page__header__title" id="introduction">
                Introduction
              </h1>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container">
              <div class="content">
                <p>
                  <em>The Imitation Game</em> surveys the extraordinary uses
                  (and abuses) of artificial intelligence<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                  (AI) in the production of contemporary visual culture. The
                  exhibition follows a chronological narrative that first
                  examines the development of artificial intelligence from the
                  1950s to the present. Building on this foundation, it then
                  emphasizes the explosive growth of AI over the past decade
                  across creative disciplines—including animation, architecture,
                  art, fashion, graphic design, urban design and video games.
                </p>
                <p>
                  From the early moments of its creation, AI has captured the
                  imaginations of cultural producers around the world. The idea
                  that machines could think and express themselves independently
                  of their human makers has been received with great skepticism,
                  some joy, and a healthy dose of anxiety.
                </p>
                <p>
                  Unsurprisingly, much of the early research on AI engaged with
                  human-centred ideas of imitation and emulation. Most notably,
                  in 1950, Alan Turing formulated an “imitation game” for
                  testing a machine’s capacity to display intelligent behaviour
                  in a manner that would be indistinguishable from natural human
                  behaviour. Around the same time, researchers began to explore
                  the possibility of an artificial neural network<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>
                  modelled directly on the human brain.
                </p>
                <p>
                  These early investigations set frameworks for much of the
                  invention that followed in the 20th century. In the past
                  decade, huge advances in the design and production of
                  computing hardware have laid the groundwork for an
                  unprecedented growth of AI as a fundamental tool with wide
                  creative applications.
                </p>
                <p>
                  The exhibition begins with an interactive introduction
                  inviting visitors to identify diverse areas of cultural
                  production influenced by AI. Twenty “objects of wonder” have
                  been selected to offer a chronological history of AI and
                  visual culture. And two special projects by artists Sougwen
                  Chung and Scott Eaton offer compelling insights into the
                  collaborative and creative powers of AI.
                </p>
                <p>
                  This exhibition is organized by the Vancouver Art Gallery and
                  curated by Bruce Grenville, Senior Curator and Glenn Entis,
                  Guest Curator
                </p>
                <br>
                <h2>An Interactive Introduction</h2>
                <figure id="interactiveintro" class="q-figure q-figure--image">
                  
                  
                  <img alt="." class="q-figure__image" src="\_assets\images\install\interactive-intro.jpg" data-outputs-include="epub,pdf">
                  <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                    <span class="q-figure__caption-content">.</span>
                    <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                      Gallery</span>
                  </figcaption>
                </figure>
                <p>
                  This interactive introduction invites visitors to explore the
                  range of images, objects and ideas that shape this exhibition.
                  Visitors may be familiar with the use of artificial
                  intelligence (AI) in their encounters with the preference
                  engines<sup class="footnote-ref"><a href="#fn3" id="fnref3">3</a></sup>
                  that select their online music, videos or shopping, but the
                  use of AI as an essential tool in a wide range of creative
                  processes is often invisible.
                </p>
                <p>
                  The interactive installation employs a basic form of AI that
                  combines computer vision, machine learning and neural networks
                  that analyze hand gestures in real time and trigger an
                  appropriate response to visitors’ interactions. The images and
                  information on this wall are addressed in greater depth
                  throughout the exhibition.
                </p>
                <p>
                  The interactive Introduction to <em>The Imitation Game</em> is
                  the result of a collaboration with Vancouver’s Centre for
                  Digital Media, under the direction of Larry Bafia. Graduate
                  students in this program worked as a team to design, program
                  and produce this wall. Many thanks to that talented team:
                </p>
                <ul>
                  <li>Allyson Zhong – Project Manager/UX</li>
                  <li>Luisa Martinez Riaño – UX/UI</li>
                  <li>Sooq Won – Video Artist/Producer</li>
                  <li>Farbod Tabaei – Concept Artist/Developer</li>
                  <li>Pieteke MacMahon – Software Developer/UX/UI Designer</li>
                  <li>Larry Bafia – team advisor and program director</li>
                </ul>
                <p>
                  Cindy Shi contributed post-production programming support.
                </p>
                <p>
                  The Centre for Digital Media was founded in 2007 and is a
                  unique graduate program whose degree is imprinted with the
                  seals of its four partner institutions: University of British
                  Columbia, Emily Carr University of Art + Design, Simon Fraser
                  University and British Columbia Institute of Technology.
                </p>
                <div class="backmatter">
                  <h2>Notes</h2>
                </div>
                <section class="footnotes">
                  <ol class="footnotes-list">
                    <li id="fn1" class="footnote-item">
                      <p>
                        Artificial Intelligence (AI) is the ability of a digital
                        computer or computer-controlled robot to perform tasks
                        commonly associated with intelligent beings.
                        <a href="#fnref1" class="footnote-backref">↩︎</a>
                      </p>
                    </li>
                    <li id="fn2" class="footnote-item">
                      <p>
                        Neural networks are computing systems with
                        interconnected nodes that work much like neurons in the
                        human brain. Using algorithms, they can recognize hidden
                        patterns and correlations in raw data, cluster and
                        classify it, and—over time—continuously learn and
                        improve.
                        <a href="#fnref2" class="footnote-backref">↩︎</a>
                      </p>
                    </li>
                    <li id="fn3" class="footnote-item">
                      <p>
                        A preference engine, or a recommender system, or a
                        recommendation system is a subclass of information
                        filtering system that seeks to predict the ‘rating’ or
                        ‘preference’ a user would give to an item.
                        <a href="#fnref3" class="footnote-backref">↩︎</a>
                      </p>
                    </li>
                  </ol>
                </section>
              </div>
              
            </div>
          </section>
        </section><section class="quire-page quire-contents" data-footer-page-title="20 Objects of Wonder" id="20-objects">
          <section class="quire-page__header hero">
            <div class="hero-body">
              <h1 class="quire-page__header__title" id="20-objects-of-wonder">
                20 Objects of Wonder
              </h1>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container">
              <div class="content">
                <p>
                  The 20 Objects of Wonder selected for
                  <em>The Imitation Game</em> offer a unique, chronological
                  insight into the history of artificial intelligence (AI),
                  including the critical advances that have shaped its present
                  configuration, and those that point the way toward its future
                  uses. Seen together, these many images, objects and events
                  reveal the breadth and depth of influence exerted by AI on
                  visual culture.
                </p>
                <p>
                  Early advances in AI laid the foundations for an intimate
                  relationship between humans and machines, and many of the
                  early theorists and researchers actively speculated on
                  fundamental questions of consciousness, creativity and
                  intelligence.
                </p>
                <p>
                  The exponential growth of computer processing capacity in the
                  past twenty years has rapidly accelerated AI research, and
                  widely distributed its use across all fields of human
                  endeavour. The increased availability of moderately priced
                  computers and sophisticated programs with accessible
                  interfaces has further expanded the reach of AI-assisted
                  thinking and making, so that today it is reasonable to say
                  that AI is a critical component of any creative practice.
                </p>
                <p>
                  From Norbert Wiener’s cybernetic moth (1949) to Neri Oxman’s
                  <em>Synthetic Apiary</em> (2020), the evolution of AI is
                  marked by a deep and abiding commitment to research,
                  experimentation and creativity.
                </p>
              </div>
            </div>

            <div class="container is-fullhd">
              <div class="quire-contents-list grid">
                
                
                <nav class="table-of-contents menu-list" data-outputs-include="pdf">
                  <ol class="table-of-contents-list">
                    <li class="level-1 page-item">
                      <a href="#20-objects-01-wieners-moth">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\1-moth1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            1. Norbert Wiener’s Moth
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-02-imitation-game">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\2-turing3.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            2. Alan Turing – The Imitation Game
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-03-space-odyssey">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\3-space-odyssey3.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            3. 2001: A Space Odyssey
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-04-cybernetic-serendipity">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\4-cybernetic-serendipity1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            4. Cybernetic Serendipity
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-05-project-cybersyn">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\5-cybersyn1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            5. Project Cybersyn
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-06-simcity">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\6-simcity1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            6. SimCity
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-07-boids-autonomous-agents">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\7-boids1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            7. Boids and Autonomous Agents
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-08-muriel-cooper">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\8-cooper1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            8. Muriel Cooper – Information Landscapes
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-09-bina48">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\9-bina48-2.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            9. Bina48
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-10-imagenet">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\10-imagenet1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            10. ImageNet
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-11-alphago">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\11-alphago1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            11. AlphaGo – Game 2 – Move 37
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-12-gan">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\12-gan1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            12. GAN
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-13-barrat-balenciaga">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\13-barrat-balenciaga1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            13. Robbie Barrat x Balenciaga
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-14-zaha-hadid-architects">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\14-morpheus-hotel1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            14. Zaha Hadid Architects – Morpehus Hotel
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-15-algorithmic-justice-league">
                        <div class="card image">
                          <div class="card-content">
                            15. Algorithmic Justice League
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-16-ai-animation">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\16-animation1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            16. AI in Animation
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-17-neri-oxman">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\17-oxman1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            17. Neri Oxman – Synthetic Apiary
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-18-smartphone">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\18-smartphone1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            18. The Smartphone
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-19-metahuman-creator">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\19-metahuman2.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            19. MetaHuman Creator
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#20-objects-20-emotion-recognition">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\20-emotion-recognition1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            20. Emotion Recognition
                          </div>
                        </div>
                      </a>
                    </li>
                  </ol>
                </nav>
                <div class="content"></div>
              </div>
              
            </div>
          </section>
        </section><section class="quire-page quire-entry" data-footer-page-title="1. Norbert Wiener’s Moth" data-footer-section-title="20 Objects of Wonder" id="20-objects-01-wieners-moth">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="moth1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\1-moth1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="moth2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\1-moth2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="moth3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\1-moth4.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-01-wieners-moth">
                    1. Norbert Wiener’s Moth
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>1949</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Norbert Wiener was an American mathematician and
                      philosopher who joined the faculty at MIT in 1919. He is
                      renowned for his collaborative work in the 1920s on early
                      computers, and during World War II was active in a small
                      group of creative interdisciplinary thinkers who produced
                      the first intelligent automated machines. This
                      interdisciplinary view spawned several new fields of
                      research including: communications, computation,
                      automation, information theory, neuroscience, and most
                      notably, cybernetics.<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                      The latter was named by Wiener in his book,
                      <em>Cybernetics: Control and Communication in the Animal
                        and the Machine</em>
                      (1948).
                    </p>
                    <p>
                      Wiener recognized the value of sharing new ideas with a
                      broad public and played the role of showman well. His
                      “Moth” has a place in a long history of mechanical animals
                      that were used to describe advances in technology and
                      design. In order to build this public representation of
                      “cybernetics,” Wiener started from the proposition that
                      all systems—organic, mechanical, social or aesthetic—are
                      defined by their ability to acquire, use, retain and
                      transmit information.
                    </p>
                    <section id="section-the-moth" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>The Moth</h2>
                      <p>
                        In the late 1940s, Norbert Wiener, then a professor at
                        MIT, teamed up with J. Wiesner (from the MIT Research
                        Laboratory of Electronics) and a fabricator named H.
                        Singleton to build a demonstration machine.
                      </p>
                      <p>
                        The machine was a three-wheeled cart with two front
                        facing photocells (sensors that detect light) and two
                        more on the sides. The output from the cells was
                        communicated to the steering mechanism on the front
                        wheel, moving the cart toward or away from a light
                        source. Depending on the intensity of the light, the
                        Moth demonstrated a jittering tremor, which closely
                        resembled animal neurological responses to stimuli
                        observed in current neuroscience studies.
                      </p>
                      <p>
                        In the images on the right, Wiener poses with the Moth
                        in a portrait for <em>Life</em> magazine; a timelapse
                        image traces the path of the Moth as it follows the
                        movement of a flashlight down a corridor; and an open
                        view of the Moth reveals its intricate construction.
                      </p>
                    </section>
                    
                    <section id="section-cybernetics-and-society" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Cybernetics and Society</h2>
                      <p>
                        In 1950, Wiener published
                        <em>The Human Use of Human Beings</em> in which he
                        decisively described the fundamental role of
                        communication in modern life:
                      </p>
                      <blockquote>
                        <p>
                          <em>It is the thesis of this book that society can only
                            be understood through a study of the messages and
                            the communication facilities which belong to it; and
                            that in the future development of these messages and
                            communication facilities, messages between man and
                            machines, between machines and man, and between
                            machine and machine, are destined to play an
                            ever-increasing part.</em>
                        </p>
                      </blockquote>
                    </section>
                    
                    <section id="section-w-grey-walter-s-tortoises" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>W. Grey Walter’s Tortoises</h2>
                      <p>
                        W. Grey Walter began his study of mechanical animals in
                        the 1940s as part of his research into the
                        neurophysiology of the brain. Walter, working
                        independently of Norbert Wiener and his circle, saw the
                        value of building simple machines that mimicked the
                        mental processes of humans and animals. Using
                        light-sensitive and touch-sensitive control mechanisms,
                        Walter’s “tortoises” responded to their
                        environment—bumping and jostling their way around a
                        room.
                      </p>
                      <p>
                        In a 1950 article for <em>Scientific American</em>,
                        entitled “An Imitation of Life,” Walter described the
                        close relationship between the animal brain and the
                        recent design of computing machines. He went on to argue
                        that his “tortoises” and their behaviours—characterized
                        by “uncertainty, randomness, free will and
                        independence”—illustrated the possibility of a machine
                        consciousness.
                      </p>
                    </section>
                    
                    <section id="section-the-hopkins-beast" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>The Hopkins Beast</h2>
                      <p>
                        The Hopkins Beast was a mobile robot built in the 1960s
                        at the Johns Hopkins University Applied Physics
                        Laboratory. Like Norbert Wiener’s Moth and Grey Walter’s
                        “tortoises,” the Hopkins Beast was cybernetic, relying
                        on signals, feedback and control systems to govern its
                        responses and movements.
                      </p>
                      <p>
                        The Hopkins Beast used photocell optics and sonar to
                        navigate the rooms and halls of the Applied Physics
                        Laboratory, while searching for black coloured charging
                        outlets that would allow it to plug-in, charge and then
                        continue its exploration. Stairways, doors, pipes and
                        other obstacles were recognized by ultrasonic
                        transducers and appropriate actions were taken to avoid
                        collision or entrapment. This demonstration of multiple
                        co-ordinated behaviours most closely resembles something
                        like the capacity of a large nucleated cell.
                      </p>
                    </section>
                    
                    <section id="section-aibo-and-spot" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Aibo and Spot</h2>
                      <p>
                        Aibo and Spot are part of a centuries-old tradition of
                        designing machine animals that hold the dual purpose of
                        introducing new technologies and delighting
                        imaginations.
                      </p>
                      <p>
                        Boston Dynamics’ Spot is a mobile robot with
                        extraordinary capacity. Unlike its predecessors, it uses
                        onboard artificial intelligence to guide its movement
                        and responses. Employing neural networks built on deep
                        learning models, Spot can analyze objects and
                        environments, and learn from its accumulated data and
                        experiences. Its incredible physical agility is
                        hilariously demonstrated in Boston Dynamics’ widely
                        shared video marketing campaigns.
                      </p>
                      <p>
                        Aibo is designed as a human companion. Its lifelike
                        movements and interactions are intended to engage its
                        human owners and to learn from those interactions. A
                        massive array of sensors all over its body feed data to
                        its facial and voice recognition software, and deep
                        learning algorithms train Aibo to respond uniquely to
                        the various individuals that might occupy a household.
                      </p>
                    </section>
                    
                    <section id="section-roomba-j7" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Roomba j7</h2>
                      <p>
                        The Roomba j7 vacuum is described as having Home
                        Intelligence—essentially an adaptive artificial
                        intelligence that allows it to map the architecture of
                        your home and to recognize and negotiate any obstacles
                        it encounters. It bears an uncanny resemblance to its
                        machine-animal predecessors and, like Grey Walter’s
                        “tortoises,” it will seek out its recharging station
                        when its battery runs low.
                      </p>
                      <p>
                        Computer-controlled by onboard software, the Roomba j7’s
                        acoustic sensors calculate the volume of dirt and adjust
                        its cleaning method accordingly. The capacity to
                        independently learn through repetition and error is
                        critical to this robot’s success.
                      </p>
                      <p>
                        Roomba and similar autonomous robotic vacuum cleaners
                        have attracted a large community of hackers who modify
                        the vacuums’ components to produce alternative
                        behaviours, or add equipment to extend their capacity.
                        Drawing machines, remote cameras, delivery bots, pet
                        minders—the opportunities are seemingly endless.
                      </p>
                    </section>
                    
                    <br>
                    <div class="backmatter"></div>
                    <section class="footnotes">
                      <ol class="footnotes-list">
                        <li id="fn1" class="footnote-item">
                          <p>
                            Norbert Wiener introduced the term ‘cybernetics’ in
                            1948 and described it as ‘the science of control and
                            communications in the animal and machine.’
                            <a href="#fnref1" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                      </ol>
                    </section>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="2. Alan Turing – The Imitation Game" data-footer-section-title="20 Objects of Wonder" id="20-objects-02-imitation-game">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="turing1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\2-turing3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="turing2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\2-turing4.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="turing3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\2-turing5.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-02-imitation-game">
                    2. Alan Turing – The Imitation Game
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>1950</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      “I propose to consider the question, ‘Can machines
                      think?’” With this deceptively simple declaration Alan
                      Turing started a conversation that has resonated for more
                      than 70 years, and has decisively shaped the development
                      of artificial intelligence.
                    </p>
                    <p>
                      Alan Turing was an English-born mathematician, computer
                      scientist, philosopher and theoretical biologist. Turing’s
                      early research provided the theoretical framework for a
                      universal computing machine. As a cryptologist at
                      Bletchley Park during World War II, he showed the power of
                      computing in mechanizing expert human procedures and
                      judgements. In the latter years of the War, he began to
                      speculate that machines could simulate the operation of
                      human brains.
                    </p>
                    <p>
                      The “Imitation Game” is the name of a test that Turing
                      sketched out in his landmark paper, “Computing Machinery
                      and Intelligence” (1950). Taking a simple party game as
                      the starting point for his analysis, Turing described a
                      scenario involving three subjects: a person, a machine and
                      an interrogator. The interrogator is placed in a separate
                      room and asked to question the machine and the person in a
                      way that will help the interrogator decide which
                      respondent is human.
                    </p>
                    <p>
                      The seeming simplicity of this test was not lost on
                      Turing, and in his paper, he also considers the validity
                      of various possible objections to his proposition: the
                      Theological Objection, the Mathematical Objection, the
                      Lady Lovelace Objection, and so on. Turing concluded his
                      paper with the observation that new developments in
                      computing machine design—including the possibility of a
                      “learning machine” based on the model of child
                      learning—should be actively pursued.
                    </p>
                    <p>
                      Ultimately, Turing intended the “Imitation Game” as a tool
                      to think about the possibility of a future computing
                      machine, and the conditions that might be needed to
                      achieve that goal.
                    </p>
                    <p>
                      Turing’s “Imitation Game,” or the Turing Test<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                      as it was later called, affirms the human mind as the
                      ideal model for the formulation of a thinking machine.
                      This isn’t a surprising conceit: humans have long imagined
                      themselves as the ideal model for most things. But Turing
                      chooses to illustrate his argument with a test that is
                      also based in doubt, confusion and ambiguity. This may be
                      a game, he seems to suggest, but what are the implications
                      of a thinking machine that could fool us into believing it
                      is human?
                    </p>
                    <section id="section-mechanical-turk" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Mechanical Turk</h2>
                      <p>
                        The history of automata (or self-operating machines) is
                        as old as human civilization, with examples of automata
                        found in China, Greece and North Africa hundreds of
                        years before the common era. Mechanical animals were a
                        favourite subject, but in 18th century Europe
                        sophisticated human automata became popular.
                      </p>
                      <p>
                        In 1770, a chess playing automaton was created by
                        Wolfgang von Kempelen. It immediately captured the
                        imagination of large audiences and toured Europe and
                        North America until it was destroyed in a fire in 1854.
                        The automaton was regarded as a skilled player and won
                        most of the games played while on tour.
                      </p>
                      <p>
                        The possibility of an intelligent machine that could
                        play chess (and defeat humans) has been a persistent
                        dream for hundreds of years, but it wasn’t until the
                        construction of IBM’s Deep Blue in 1997 that machines
                        consistently achieved that goal. Von Kempelen’s
                        Mechanical Turk<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>
                        was unfortunately a ruse; the machine was in fact guided
                        by the hand of a human chess-master who was elaborately
                        hidden in the interior of the cabinet.
                      </p>
                      <p>
                        Dressed in Ottoman robes and a turban, Von Kempelen’s
                        automaton was dubbed the casually racist moniker “the
                        Mechanical Turk,” undoubtedly with the intent to
                        acknowledge the early adoption of chess in Persia and
                        the Middle East. It was also just as likely an attempt
                        to appeal to the exoticism and Orientalism that
                        persistently shaped European perceptions of the Middle
                        East during the 18th and 19th centuries.
                      </p>
                      <div class="backmatter"></div>
                      <section class="footnotes">
                        <ol class="footnotes-list">
                          <li id="fn2" class="footnote-item">
                            <p>
                              The Turk, also known as the Mechanical Turk or
                              Automaton Chess Player, was a fake chess-playing
                              machine constructed in the late 18th century.
                              <a href="#fnref2" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                        </ol>
                      </section>
                    </section>
                    
                    <section id="section-ada-lovelace" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Ada Lovelace</h2>
                      <p>
                        Citing the likely objections of Ada Lovelace to his
                        question “Can machines think?,” Alan Turing devoted a
                        subsection of his “Computing Machinery” paper to her
                        thoughts on the likelihood of an “engine” that might
                        compose or weave according to its own criteria. It is a
                        remarkable “conversation” in which Turing anticipates
                        and counters what he imagines would be Lovelace’s
                        objections, nearly 100 years after her death.
                      </p>
                      <p>
                        Lovelace was a mathematician, scientist and writer who
                        worked closely with Charles Babbage, the inventor of the
                        Difference Engine (a mechanical calculator), and the
                        Analytical Engine (essentially a programmable computer).
                        In 1843, in her notes for a published translation of
                        Babbage’s 1840 lecture on the analytical Engine,
                        Lovelace speculated on the engine’s potential use on
                        things other than numbers:
                      </p>
                      <blockquote>
                        <p>
                          <em>Supposing, for instance, that the fundamental
                            relations of pitched sounds in the science of
                            harmony and of musical composition were susceptible
                            of such expression and adaptations, the engine might
                            compose elaborate and scientific pieces of music of
                            any degree of complexity or extent.</em>
                        </p>
                      </blockquote>
                      <p>
                        In other notes, Lovelace expresses doubt that the engine
                        could be truly creative or produce something new.
                        Rather, she believes that the engine would compose only
                        what it was instructed to compose. Turing acknowledges
                        why Lovelace might make this objection, but also offers
                        a counter argument: we should be open to “surprises”
                        when considering the capacity of machines, and that
                        creativity (a “creative mental act”) was certainly not
                        out of the question, especially in the case of a
                        “learning machine.”
                      </p>
                    </section>
                    
                    <section id="section-the-voight-kampff-machine-test" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>The Voight-Kampff Machine Test</h2>
                      <p>
                        In 1982, Ridley Scott adapted Philip K. Dick’s 1968
                        novel <em>Do Androids Dream of Electric Sheep?</em> to
                        produce the film <em>Blade Runner</em>. It is a
                        dystopian story set in a near future (2019) in which
                        synthetic humans called “replicants” have escaped from
                        their job as forced labourers on distant off-world
                        colonies. Rick Deckard is a retired “blade runner”
                        brought back to hunt down a particularly virulent group
                        of replicants.
                      </p>
                      <p>
                        The replicants are bio-engineered androids—highly
                        sophisticated robots made of flesh-like material—who
                        have begun to show increasing independence of thought
                        and highly complex emotions. Some replicants have been
                        given false memories and have no awareness of their
                        identity.
                      </p>
                      <p>
                        Deckard, and other blade runners, administer a test—the
                        Voight-Kampff Test—to distinguish between humans and
                        replicants. It is, of course, a Turing Test, but with
                        ominous consequences, as the discovered replicants are
                        quickly and violently dispatched. The test used in the
                        film has many of the characteristics of a polygraph or
                        lie detector test, but with a focus on empathy rather
                        than intelligence. The questions asked by the
                        interrogator are emotionally charged; the replicant’s
                        response is measured by observing breathing, heart rate
                        and pupillary response.
                      </p>
                      <p>
                        Syd Mead was a renowned concept artist whose futuristic
                        visions gave shape to a wide range of films including
                        <em>Blade Runner</em> (1982), <em>Tron</em> (1982),
                        <em>Aliens</em> (1986), and
                        <em>Johnny Mnemonic</em> (1995). For these films he
                        developed the look of entire cities, crowded
                        streetscapes, and elaborate electronic vehicles and
                        equipment that gave a gritty realism to even the most
                        fantastical ideas.
                      </p>
                      <p>
                        Mead’s concept drawing for the Voight-Kampff machine is
                        at once futuristic and anachronistic. It is an intricate
                        automated device with 19th century embellishments such
                        as mechanical bellows and a stylized monocle. In the
                        hands of Rick Deckard, the interrogator who administers
                        the Voight-Kampff test, the machine is a menacing beast
                        that appears to breathe and move of its own accord.
                      </p>
                    </section>
                    
                    <br>
                    <div class="backmatter"></div>
                    <section class="footnotes">
                      <ol class="footnotes-list">
                        <li id="fn1" class="footnote-item">
                          <p>
                            The Turing test, originally called ‘the imitation
                            game’ by Alan Turing in 1950, is a test of a
                            machine’s ability to exhibit intelligent behavior
                            equivalent to, or indistinguishable from, that of a
                            human.
                            <a href="#fnref1" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                      </ol>
                    </section>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="3. 2001: A Space Odyssey" data-footer-section-title="20 Objects of Wonder" id="20-objects-03-space-odyssey">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="odyssey1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\3-space-odyssey3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="odyssey2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\3-space-odyssey2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="odyssey3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\3-space-odyssey5.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="odyssey4" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\3-space-odyssey6.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-03-space-odyssey">
                    3. 2001: A Space Odyssey
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>1968</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      <em>2001: A Space Odyssey</em> (1968) is a landmark in the
                      representation of artificial intelligence in visual
                      culture. From the earliest moments of the film, we are
                      cast about in space and time in ways that distort and
                      upend our perceptions of reality. At the centre of the
                      film is the HAL 9000 computer. HAL is the acronym for a
                      Heuristically programmed Algorithmic computer—which is to
                      say, a computer optimized for problem solving,
                      self-discovery and decision-making, though inherently
                      vulnerable to error. It is adept at independently
                      controlling complex machines, interacting with humans in
                      ways that would certainly pass the Turing Test, and using
                      computer vision to track a wide range of activities,
                      including the reading of lips.
                    </p>
                    <p>
                      Left to its own devices, HAL suspects that the humans are
                      sabotaging the planned mission to Jupiter, and it begins
                      to restrict their control, finally deciding to kill them
                      in order to save the mission. But Bowman narrowly escapes,
                      and makes his way to HAL’s computer processing core where
                      he methodically disconnects the various circuits that
                      produce HAL’s consciousness. HAL maintains a calm and
                      controlled voice trying to assure Bowman that it can
                      change its plan. But as Bowman slowly deactivates HAL’s
                      memory, it begs Bowman to stop, expressing its fear, its
                      feeling of loss—then finally devolving to its earliest
                      operational state.
                    </p>
                    <p>
                      At this point in the film, viewers are invited to consider
                      our limited assumptions about the nature of sentience,
                      and, specifically, its formation in machines.
                    </p>
                    <p>
                      The film’s director, Stanley Kubrick, and his co-writer
                      for the screenplay, Arthur C. Clarke, conceived of an
                      artificial intelligence that had achieved a consciousness
                      that closely resembled that of humans—recognizing within
                      this a very real likelihood of fallibility.
                    </p>
                    <p>
                      The question of fallibility and error(s) in judgement
                      produced by the actions of an artificial intelligence is a
                      persistent theme, from the 1950s onward, in literature,
                      art and, most notably, film.
                    </p>
                    <section id="section-samuel-butler" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Samuel Butler</h2>
                      <p>
                        Samuel Butler was a British novelist and cultural
                        critic. His novel
                        <em>Erewhon: or, Over the Range</em> was published
                        anonymously in 1872 and takes the form of a utopian
                        narrative of place. Three chapters in the book are
                        identified as “The Book of Machines,” and they describe
                        a society with a conflicted relationship to machines.
                        Citing Charles Darwin’s theories on evolution, Butler
                        represents a world with machines that have evolved
                        consciousness and threaten to transform in ways that
                        cannot be controlled by humans:
                      </p>
                      <blockquote>
                        <p>
                          <em>I would repeat that I fear none of the existing
                            machines; what I fear is the extraordinary rapidity
                            with which they are becoming something very
                            different to what they are at present. No class of
                            beings have in any time past made so rapid a
                            movement forward. Should not that movement be
                            jealously watched, and checked while we can still
                            check it? And is it not necessary for this end to
                            destroy the more advanced of the machines which are
                            in use at present, though it is admitted that they
                            are in themselves harmless?</em>
                        </p>
                      </blockquote>
                    </section>
                    
                    <section id="section-the-matrix" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>The Matrix</h2>
                      <p>
                        The Wachowskis’ film, <em>The Matrix</em> (1999), set
                        new standards in the use of computer driven special
                        effects in film, and offered an enduringly tangible
                        representation of a simulated world run by an artificial
                        intelligence.
                      </p>
                      <p>
                        Dreams play an integral part in our perception of
                        consciousness. At its furthest extension, the world of
                        dreams opens the door to the possibility that the world
                        we experience is itself a dream.
                        <em>The Matrix</em> takes this ancient narrative and
                        turns it toward the world of artificial intelligence.
                        What if our lives are nothing more than a highly
                        effective virtual reality seamlessly rendered by a very
                        powerful computer? Once again, the narrative of an
                        all-controlling artificial intelligence challenges our
                        complacency and demands vigilance over the machine.
                      </p>
                      <p>
                        The special effects in <em>The Matrix</em> are
                        legendary. By using complex virtual cinematography to
                        choreograph the real camera movements, they were able to
                        achieve new and compelling camera angles that give the
                        film its otherworldliness. And give us yet another
                        instance of the virtual world seizing control of the
                        real world.
                      </p>
                    </section>
                    
                    <section id="section-ex-machina" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Ex Machina</h2>
                      <p>
                        This scene from the 2014 film <em>Ex Machina</em> by
                        writer and director Alex Garland describes an encounter
                        between Caleb and Ava. Caleb is a young programmer who
                        has been brought to the home of Nathan, a wealthy
                        software developer, to test the capacity of a new robot
                        with artificial intelligence named Ava. In an early
                        meeting, Caleb asks Ava a series of questions that
                        recall the parameters of a Turing Test. Ava later turns
                        the tables on Caleb by asking a series of penetrating
                        questions that reveal a compelling intelligence on its
                        part. The larger narrative of the film is also
                        introduced in this scene when Ava warns Caleb that the
                        developer is a dangerous liar.
                      </p>
                      <p>
                        The conventional narrative of a dangerous artificial
                        intelligence is here played in reverse; Nathan, and not
                        the robot, is the threatening and unpredictable
                        consciousness that seeks to control the world. But in
                        his representation of artificial intelligence, Garland
                        seems unable to move beyond the conventions of overt
                        sexualization and gendered stereotyping used in the
                        depiction of robots, and, apparently, software
                        developers.
                      </p>
                    </section>
                    
                    <section id="section-ben-bogart" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Ben Bogart</h2>
                      <p>
                        Ben Bogart’s video installation
                        <em>Watching (2001: A Space Odyssey)</em> offers an
                        intricate interaction with Stanley Kubrick’s film
                        <em>2001: A Space Odyssey</em>. This interaction takes
                        the form of an active watching in which the image and
                        sound of the original film are disassembled and then
                        reconstituted using complex algorithms embedded in
                        statistically oriented machine learning<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                        and computer vision<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>
                        programs.
                      </p>
                      <p>
                        The reconstituted film is strangely familiar but the
                        space and time that it describes is ordered in a new and
                        compelling way. Those who have seen Kubrick’s version
                        may struggle to reconcile the old with the new, but the
                        reward comes in surrendering one’s preconceptions, and
                        watching closely the pattern, movement and sounds
                        rendered by Bogart’s artificial intelligence.
                      </p>
                      <p>
                        In this unexpected way, we are offered the surprising
                        opportunity to witness an artificial intelligence
                        “watching” a film, which is itself a study of artificial
                        intelligence, consciousness and perception, across space
                        and time.
                      </p>
                      <div class="backmatter"></div>
                      <section class="footnotes">
                        <ol class="footnotes-list">
                          <li id="fn1" class="footnote-item">
                            <p>
                              Machine learning is an application of AI that
                              enables systems to learn and improve from
                              experience without being explicitly programmed.
                              <a href="#fnref1" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                          <li id="fn2" class="footnote-item">
                            <p>
                              Computer vision is a field of artificial
                              intelligence that enables computers and systems to
                              derive meaningful information from digital images,
                              videos and other visual inputs.
                              <a href="#fnref2" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                        </ol>
                      </section>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="4. Cybernetic Serendipity" data-footer-section-title="20 Objects of Wonder" id="20-objects-04-cybernetic-serendipity">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="serendipity1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\4-cybernetic-serendipity1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-04-cybernetic-serendipity">
                    4. Cybernetic Serendipity
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>1968</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      <em>Cybernetic Serendipity: The Computer and the Arts</em>
                      was a landmark exhibition mounted at the Institute of
                      Contemporary Arts (ICA), London, in 1968, and organized by
                      Jasia Reichardt, curator and associate director of the
                      ICA.
                    </p>
                    <p>
                      Drawing on the term “cybernetics” that had been
                      popularized by Norbert Wiener twenty years earlier, the
                      exhibition explored the potential for advanced
                      technologies to enable new modes of creativity. This was a
                      new age of interdisciplinarity, and the exhibition
                      highlighted collaborations between more than 300 artists,
                      composers, performers, scientists and engineers. The
                      concept of “serendipity” was a theme taken up in many of
                      the individual works, and notions of play, chance and
                      surprise were common threads throughout.
                    </p>
                    <p>The exhibition was divided into three sections:</p>
                    <ul>
                      <li>
                        <p>
                          Computer-generated graphics, computer-animated films,
                          computer-composed and played music, and computer poems
                          and texts;
                        </p>
                      </li>
                      <li>
                        <p>
                          Cybernetic devices as works of art, cybernetic
                          environments, remote control robots and painting
                          machines;
                        </p>
                      </li>
                      <li>
                        <p>
                          A “learning zone” with machines demonstrating the uses
                          of computers, and an environment dealing with the
                          history of cybernetics.
                        </p>
                      </li>
                    </ul>
                    <p>
                      The extensive catalogue for the
                      <em>Cybernetic Serendipity</em> exhibition was first
                      published in 1968 as a special issue of
                      <em>Studio International</em>, an influential art magazine
                      based in London. Under the editorial leadership of Peter
                      Townsend, <em>Studio International</em> endorsed
                      interdisciplinary practices, new technologies and an
                      international community of cultural producers.
                    </p>
                    <p>
                      With more than 100 pages and 300 images—and featuring
                      contributions by dozens of experts in various fields—the
                      publication was both a primer on the history of the
                      computer, and an avant-garde statement on the uses of new
                      technologies in art, music, poetry, dance, graphics,
                      architecture, installation, and environmental art and
                      film.
                    </p>
                    <p>
                      The cover of the catalogue and exhibition poster, which
                      incorporated computer graphics from the exhibition, was
                      designed by the Polish-British painter, filmmaker and
                      stage designer Franciszka Themerson.
                    </p>
                    <p>
                      Much of the original exhibition was subsequently shown at
                      the Corcoran Annex in Washington, D.C., and then at the
                      newly opened Exploratorium in San Francisco in 1969.
                    </p>
                    <section id="section-john-h-whitney-permutations" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>John H. Whitney, Permutations</h2>
                      <p>
                        John H. Whitney was an animator, filmmaker and key
                        figure in the early development of computer graphics.
                        His collaboration on the animated title sequence for
                        Alfred Hitchcock’s <em>Vertigo</em> in 1958 was widely
                        acknowledged for its innovation and dynamic
                        imagery—including the spirographic images (based on the
                        mathematical forms known as Lissajous curves<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>) that also feature prominently in
                        <em>Permutations</em>.
                      </p>
                      <p>
                        Whitney saw the computer as a fundamental tool to link
                        music and visual art. Through the use of sound and
                        computer graphics, he created harmonic events in
                        audio-visual presentations. He describes the process as
                        follows:
                      </p>
                      <blockquote>
                        <p>
                          <em>In</em> Permutations
                          <em>each point moves at a different speed and moves in
                            a direction independent according to natural laws
                            quite as valid as those of Pythagoras, while moving
                            in their circular field. Their action produces a
                            phenomenon more or less equivalent to the musical
                            harmonies. When the points reach certain
                            relationships (harmonic) numerical to other
                            parameters of the equation, they form elementary
                            figures.</em>
                        </p>
                      </blockquote>
                      <div class="backmatter"></div>
                      <section class="footnotes">
                        <ol class="footnotes-list">
                          <li id="fn1" class="footnote-item">
                            <p>
                              A Lissajous curve is the graph of a system of
                              parametric equations which describe complex
                              harmonic motion.
                              <a href="#fnref1" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                        </ol>
                      </section>
                    </section>
                    
                    <section id="section-tony-pritchett-the-flexipede" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Tony Pritchett, The Flexipede</h2>
                      <p>
                        <em>The Flexipede</em> had its premiere in
                        <em>Cybernetic Serendipity</em>, and was reputed to be
                        the first computer-generated animated film made in the
                        UK. Tony Pritchett produced it on the University of
                        London’s Atlas Computer (one of the world’s first
                        supercomputers) using FORTRAN IV—a programming language
                        that was employed in computationally intensive research,
                        such as numerical weather prediction, finite element
                        analysis, computational fluid dynamics, and so on.
                        FORTRAN IV was widely used by artists and programmers in
                        the <em>Cybernetic Serendipity</em> exhibition.
                      </p>
                      <p>
                        Pritchett wrote the subroutines (program instructions)
                        using punch cards, then transferred the output to tape
                        using a FORTRAN-based graphics software package called
                        GHOST. The tapes were used to produce an output on a
                        plotter printer and then filmed by a microfilm recorder.
                      </p>
                    </section>
                    
                    <section id="section-alison-knowles-the-house-of-dust" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Alison Knowles, The House of Dust</h2>
                      <p>
                        Alison Knowles is renowned for her work as an artist in
                        a diverse range of media including performance,
                        installation, sound works and publications. She was a
                        founding member of Fluxus—an international,
                        interdisciplinary group of artists, composers, designers
                        and poets active during the 1960s. Her poem,
                        <em>The House of Dust</em>, was conceived in
                        collaboration with James Tenney, a composer-in-residence
                        at Bell Labs in New Jersey, and an expert on the IBM
                        compiling system known as FORTRAN.
                      </p>
                      <p>
                        Knowles’ interest in chance and indeterminacy coincided
                        with Tenney’s interest in the manipulation and
                        generation of information, and their collaboration was
                        first shown in <em>Cybernetic Serendipity</em>. It took
                        the form of computer-generated poems compiled in four
                        randomly generated lines—indicating a type of house; a
                        material, a site or situation; a light source; and a
                        category of inhabitants.
                      </p>
                      <p>
                        The resulting poems are surprisingly evocative, and full
                        of humour and absurdity. For Knowles, they also offered
                        an opportunity for a compelling meditation on dwelling
                        and architecture. In 1968, she designed and built
                        <em>The House of Dust</em> structure, later installing
                        it at CalArts in Valencia, California, when she moved
                        there to teach in 1969.
                      </p>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="5. Project Cybersyn" data-footer-section-title="20 Objects of Wonder" id="20-objects-05-project-cybersyn">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="cybersyn1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\5-cybersyn1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="cybersyn2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\5-cybersyn2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="cybersyn3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\5-cybersyn3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="cybersyn4" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\5-cybersyn4.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-05-project-cybersyn">
                    5. Project Cybersyn
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>1971–73</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Using some of the basic principles of cybernetics
                      theory—communication and control—Stafford Beer, a
                      consultant to the newly-elected Salvador Allende
                      government (1970–73), devised a plan to enable a dynamic,
                      socialist-driven transformation of the Chilean economy.
                    </p>
                    <p>
                      Building on Jay Forrester’s theories of system
                      dynamics<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>, and specifically his book
                      <em>Industrial Dynamics</em> (1961), Beer laid out a
                      strategy to capture information feedback from workers,
                      managers, suppliers, shippers and consumers across the
                      country. This data was used to produce a list of relevant
                      indicators that could be monitored and, in turn, used to
                      make adjustments in planning or to redirect goods and
                      supplies.
                    </p>
                    <p>
                      Project Cybersyn was composed of four key elements: a
                      national network of teletype machines that would capture
                      information in real time; an IBM System/360 Model 50
                      computer (1965) running a purpose-built version of Dynamo
                      software for simulating system dynamics models; an
                      Operations Room where ongoing analysis of the received
                      data would provide key indicators; and the resulting
                      indicators used to provide feedback to the producers,
                      shippers and consumers, and to make necessary adjustments.
                    </p>
                    <p>
                      After two years of development, Project Cybersyn launched
                      in February 1973. Beer struggled to maintain the project’s
                      goal for greater worker autonomy within a system that was
                      consultative at all levels. These concerns, however, were
                      overshadowed by the Allende government’s struggle to
                      maintain its autonomy. In September 1973, Allende was
                      murdered in a CIA-backed military coup led by General
                      Pinochet, and the Cybersyn Operations Room was destroyed.
                    </p>
                    <section id="section-the-operations-room" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>The Operations Room</h2>
                      <p>
                        The Operations Room was a key element of Project
                        Cybersyn. Symbolically, its design by Gui Bonsiepe
                        reflected the forward thinking modernism that informed
                        the project as a whole. The Operations Room was a nexus
                        for the information that flowed in and out of the
                        teletypes and mainframe computer. The design team was
                        led by Bonsiepe—a German-born designer trained at the
                        famed Ulm School of Design—who was working as a design
                        consultant in South America during the 1970s. When the
                        Room was up and running in early 1973, a small team of
                        designers were also employed to design the data
                        projected on the screens in real time.
                      </p>
                      <p>
                        Reflecting Bonsiepe’s training at Ulm, the Room was
                        designed with a strict adherence to the principles of
                        gestalt design—closure, proximity, similarity,
                        continuity, perception, organization and symmetry. The
                        seven swivel chairs allow the whole Room to be seen in a
                        glance, and support intimate, egalitarian conversation.
                      </p>
                      <p>
                        The annotated images used in the video slideshow are a
                        selection of drawings, diagrams and photographic
                        documentation that offer some insights into the planning
                        and design of Project Cybersyn.
                      </p>
                    </section>
                    
                    <section id="section-designing-freedom" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Designing Freedom</h2>
                      <p>
                        In this excerpt from Stafford Beer’s Massey Lectures for
                        CBC Radio (1973), Beer concludes the six-part series
                        with a plea to recognize the fundamental role of new
                        technologies in designing new models of freedom; and the
                        threat to that freedom if those technologies are
                        mishandled. This conclusion to the lecture series was
                        hastily revised to acknowledge the ongoing coup in
                        Chile. Using the language of cybernetics theory, Beer
                        cites the actions of the Pinochet junta as “the output
                        of a system designed to curb liberty, my message is that
                        we must redesign that system to produce freedom as an
                        output.”
                      </p>
                    </section>
                    
                    <section id="section-simulacron-3-and-the-tunnel-under-the-world" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Simulacron-3 and The Tunnel under the World</h2>
                      <p>
                        Daniel F. Galouye’s <em>Simulacron-3</em> tells the
                        story of a computer-generated city simulation that was
                        created to fill the needs of a marketing research
                        company. The simulation is so realistic that the city’s
                        inhabitants don’t realize they are living in a virtual
                        world.
                      </p>
                      <p>
                        Frederick Pohl’s short story, “The Tunnel under the
                        World,” is an early example of a simulated world built
                        by a corporate entity that uses the town’s
                        inhabitants—recently annihilated in an industrial
                        accident and<br>
                        recreated as minuscule robots—to test hard sell
                        marketing strategies.
                      </p>
                      <p>
                        These stories are part of a science fiction subgenre,
                        which emerged in the 1950s and 60s and addressed a
                        growing and unregulated world of corporate marketing and
                        research based in computer intensive systems analysis.
                        This marketing research was rooted in an analysis of the
                        values, choices and desires of increasingly large
                        segments of population. Data gathered through polls,
                        interviews and consumer sales was used to build massive
                        simulations that would confidently predict the future.
                      </p>
                    </section>
                    
                    <section id="section-world-on-a-wire" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>World on a Wire</h2>
                      <p>
                        <em>World on a Wire</em> was a two-part television
                        miniseries directed by Rainer Werner Fassbinder and made
                        for German television. Inspired by Daniel F. Galouye’s
                        novel <em>Simulacron-3</em> (1964), Fassbinder’s film
                        depicts a near-future world in which the Cybernetics and
                        Future Science Institute runs a massive virtual world on
                        its supercomputer named Simulacron. The world contains
                        thousands of “identity units” who exist and go about
                        their everyday lives oblivious of the fact that they are
                        simulations.
                      </p>
                      <p>
                        In the video excerpt shown here, the newly appointed
                        director of the Institute, Dr. Fred Stiller, enters the
                        simulation to investigate a sudden death (the
                        Institute’s previous director) and a rogue unit named
                        Einstein. Einstein has become self-aware and realizes
                        that he is a simulation. He begs Stiller to take him to
                        the real world.
                      </p>
                      <p>
                        The notion of a hidden, simulated world is a consistent
                        trope in the narratives of artificial intelligence.
                        <em>World on a Wire</em> tells the story of a scientific
                        institute that uses a simulation program to predict the
                        future of steel prices for a giant corporation. And its
                        source material, Galouye’s
                        <em>Simulacron-3,</em> pointed to the world of marketing
                        and its use of simulations to predict trends. Both drew
                        on a growing public awareness of the power of computing
                        and the manipulation of public opinion in real life
                        through entities such as the Simulmatics Corporation,
                        which played a critical role in American politics and
                        the Vietnam War during the 1960s.
                      </p>
                    </section>
                    
                    <br>
                    <div class="backmatter"></div>
                    <section class="footnotes">
                      <ol class="footnotes-list">
                        <li id="fn1" class="footnote-item">
                          <p>
                            System dynamics (SD) is an approach to understanding
                            the nonlinear behaviour of complex systems over time
                            using stocks, flows, internal feedback loops, table
                            functions and time delays.
                            <a href="#fnref1" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                      </ol>
                    </section>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="6. SimCity" data-footer-section-title="20 Objects of Wonder" id="20-objects-06-simcity">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="simcity1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\6-simcity1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-06-simcity">
                    6. SimCity
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>1989</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Different than a typical computer game,
                      <em>SimCity</em> is a city simulator—each player (or
                      “SimCity Mayor”) designs and manages their own city,
                      placing buildings, roads, railroads and power lines;
                      setting civic spending priorities; and making key policy
                      decisions such as tax rates, zoning, and the construction
                      of prisons or military facilities. For many players, the
                      potential disasters—earthquakes, tornadoes, fires and even
                      giant monsters—were the most fun part of the gaming
                      experience. <em>SimCity</em> has been credited with
                      inspiring a generation of urban planners and government
                      officials.
                    </p>
                    <p>
                      Urban planning and governance are highly complex and
                      fraught with unforeseen interactions and outcomes.
                      Consequently, this area was an early topic of interest for
                      the application of computer simulations and artificial
                      intelligence, notably in the early research and
                      publications of Jay Forrester. More recently, focus has
                      shifted from simulating possible outcomes to using AI
                      programs to monitor and control various systems in
                      real-life cities. Google Sidewalk Labs’ Sidewalk Toronto
                      project offers a striking representation of the issues
                      raised by this recent development in urban design.
                    </p>
                    <p>
                      The original 1989 edition of <em>SimCity</em> introduced
                      the basic components that would evolve throughout the
                      25-year lifetime of the game. Through simple, colourful
                      graphics, <em>SimCity</em> put the power of computer
                      simulation into the hands of millions.
                    </p>
                    <p>
                      These video clips present a sample of the features in the
                      original 1989 edition. On a simple map, players can design
                      and manage a city; watch it grow (sometimes in unexpected
                      ways, similar to the pioneering urban simulations of Jay
                      Forrester); and respond to a rich and entertaining set of
                      disasters. <em>SimCity</em>, in contrast to most computer
                      games of the era, was open-ended, noncompetitive and
                      impossible to win or lose, leading the publisher to market
                      it as a “software toy.”
                    </p>
                    <p>
                      <em>SimCity</em>’s creator, Will Wright, went on to create
                      <em>The Sims</em> and <em>Spore</em>, and pioneered an
                      entire genre of simulator-based games.
                    </p>
                    <section id="section-jay-forrester" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Jay Forrester</h2>
                      <p>
                        Jay Forrester pioneered the field of system dynamics—the
                        use of computer simulations to model complex systems and
                        interactions. One of the areas that he and his
                        colleagues at MIT tackled was urban dynamics—the
                        behaviour and sometimes surprising interactions of the
                        various policies and processes that shape a city.
                        Forrester’s dedication to clear mental models and
                        rigorous computer simulations produced an early and
                        influential real-world use of computer intelligence.
                      </p>
                      <p>
                        After publishing <em>Urban Dynamics</em> in 1969, he
                        expanded his work to a global scale, tackling issues of
                        world economy, population and the environment in
                        <em>World Dynamics</em>, published in 1971. Here, he
                        notably predicts the collapse of our
                        socio-technological-natural system by the mid-21st
                        century. In addition to influencing a generation of
                        urban planners and computer scientists, Forrester has
                        been cited by game designer Will Wright as one of the
                        main inspirations behind the urban simulation video
                        game, <em>SimCity</em>.
                      </p>
                    </section>
                    
                    <section id="section-sidewalk-labs" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Sidewalk Labs</h2>
                      <p>
                        A “Smart City” uses technology to collect information,
                        make decisions and manage municipal processes
                        intelligently. In contrast to the purely “what if”
                        simulations of Jay Forrester and the video game,
                        <em>SimCity</em>, Smart City systems are taking on a
                        growing role in the actual management of many facets of
                        urban life—transportation, power, water, health
                        services, zoning, crime detection, and, most
                        controversially, surveillance. AI and the Internet of
                        Things (IoT)—things not normally considered to be
                        computers connected to the internet—combine to create a
                        vision of a city as a linked information system whose
                        management can be analyzed and optimized by AI
                        algorithms. Among the many examples of Smart City
                        initiatives, Sidewalk Toronto, which launched in 2015
                        (and abruptly ended in 2020), was notable for the number
                        of commercial spin-offs it generated. The video
                        displayed here shows glimpses of three such spin-offs:
                      </p>
                      <p>
                        <strong>Pebble:</strong> real time parking coordination
                        and management
                      </p>
                      <p>
                        <strong>Delve:</strong> generative design and analysis
                        of building developments
                      </p>
                      <p>
                        <strong>Mesa:</strong> smart optimization of energy
                        usage within building
                      </p>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="7. Boids and Autonomous Agents" data-footer-section-title="20 Objects of Wonder" id="20-objects-07-boids-autonomous-agents">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="boids1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\7-boids1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-07-boids-autonomous-agents">
                    7. Boids and Autonomous Agents
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>1987</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      In 1987, Craig Reynolds, an AI and computer graphics
                      researcher, introduced “boids,”<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                      a program that simulates complex flocking motions—the
                      collective motion of self-propelled entities like
                      birds—using simple rules that would allow each “boid” to
                      act as an independent agent.
                    </p>
                    <p>
                      The complex flocking motion that resulted from these
                      simple rules surprised both Reynolds and the computer
                      graphics community. “Boids,” and the creation of emergent
                      complex motion through the application of relatively
                      simple rules to large numbers of autonomous agents, became
                      an influential concept that was adopted and extended by
                      many researchers, software developers and special effects
                      artists.
                    </p>
                    <p>
                      Are “boids” really artificial intelligence, or simply
                      clever algorithmic<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>
                      constructions that produce the illusion of complex
                      behaviour without any underlying understanding? It is a
                      subject of some debate, yet the same question can be asked
                      of any AI system. Recalling Alan Turing’s “Imitation
                      Game,” it may be sufficient to say that animating with
                      autonomous agents creates the illusion of life on a grand
                      scale—one that has fooled even expert human observers.
                    </p>
                    <p>
                      The three rules (or steering behaviours) for “boids” were
                      simple:
                    </p>
                    <ul>
                      <li>
                        <p>
                          <strong>separation:</strong> steer to avoid crowding
                          local flockmates
                        </p>
                      </li>
                      <li>
                        <p>
                          <strong>alignment:</strong> steer toward the average
                          heading of local flockmates
                        </p>
                      </li>
                      <li>
                        <p>
                          <strong>cohesion:</strong> steer to move toward the
                          average position (centre of mass) of local flockmates
                        </p>
                      </li>
                    </ul>
                    <p>
                      “Boids” was first presented by Craig Reynolds in 1986 as a
                      technical paper at SIGGRAPH, the prestigious annual
                      computer graphics conference. In 1987, Reynolds premiered
                      a short computer animated film,
                      <em>Stanley &amp; Stella</em>, which featured a flock of
                      birds and a school of fish animated using the
                      "boids"algorithm. In 1998, Reynolds was honored
                      with an Academy of Motion Pictures Scientific and
                      Technical Award in recognition of “his pioneering
                      contributions to the development of three-dimensional
                      computer animation for motion picture production.”
                    </p>
                    <section id="section-weta" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>WETA</h2>
                      <p>
                        WETA is the New Zealand-based studio responsible for the
                        spectacular special effects for the
                        <em>Lord of the Rings</em> films, among many others. The
                        crowd scenes produced by WETA are among the most
                        influential and sophisticated applications of Craig
                        Reynolds’ “boids” algorithm. In the WETA generated
                        scenes shown here, thousands of orcs, humans, dragons
                        and other creatures are visible at the same time,
                        exhibiting varied and complex action that would be
                        impossible for human animators to produce. These
                        extraordinary scenes offer a sophisticated balance of
                        fantastical scale and believable behaviour, satisfying
                        both our imaginations and our rational minds.
                      </p>
                    </section>
                    
                    <section id="section-autonomous-vehicles" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Autonomous Vehicles</h2>
                      <p>
                        Autonomous vehicles are another example of a flock of
                        independent agents. The underlying idea is the same,
                        although the sophistication necessary to guide a vehicle
                        is vastly greater than that required for “boids” or
                        movie special effects. Computer vision, ultrasonic
                        sensors, LiDAR (Light Detection and Ranging) and radar,
                        GPS, and up-to-date detailed mapping all must be fast,
                        accurate and reliable. If a “boid” or a special effects
                        soldier collides, no one gets hurt. This is not the case
                        with vehicles, where a single collision could prove
                        lethal. Not surprisingly, there are spirited debates
                        regarding the ethical and moral challenges posed by
                        fully autonomous vehicles.
                      </p>
                    </section>
                    
                    <br>
                    <div class="backmatter"></div>
                    <section class="footnotes">
                      <ol class="footnotes-list">
                        <li id="fn1" class="footnote-item">
                          <p>
                            Boids is an artificial program, developed by Craig
                            Reynolds in 1986, which simulates the flocking
                            behaviour of bids.
                            <a href="#fnref1" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                        <li id="fn2" class="footnote-item">
                          <p>
                            An algorithm is a set of instructions or a recipe
                            for solving a problem or accomplishing a task.
                            <a href="#fnref2" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                      </ol>
                    </section>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="8. Muriel Cooper – Information Landsc" data-footer-section-title="20 Objects of Wonder" id="20-objects-08-muriel-cooper">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="cooper1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\8-cooper1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="cooper2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\8-cooper2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="cooper3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\8-cooper4.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-08-muriel-cooper">
                    8. Muriel Cooper – Information Landscapes
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>1994</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      In 1973, Muriel Cooper founded the Visible Language
                      Workshop (VLW) at MIT, where she played a pivotal role in
                      the exploration of computer graphics and typography in
                      modern design. The principal mission of the VLW was to
                      develop design strategies and devices for manipulating
                      information in dynamic contexts. In 1985, the VLW was
                      amalgamated with MIT’s Architecture Machine Group and the
                      Center for Advanced Visual Studies to form the MIT Media
                      Lab, which became one of the most influential centres for
                      the study of artificial intelligence in the world.
                    </p>
                    <p>
                      One of Cooper’s key areas of interest was responsive
                      design<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                      systems, incorporating feedback (in the cybernetic sense)
                      into the design process—feedback that responded
                      dynamically to the environment (space and context) of the
                      design. She also focused on layering information, again
                      using 3D space (advancing, receding, rotating) as a key
                      design element.
                    </p>
                    <p>
                      Today, it is hard to imagine a time before 3D graphic
                      design, but Cooper was the leading proponent of a new
                      field of visual design. Her work broke the flat space of
                      conventional design and replaced it with a new interface
                      that had depth and movement, and was responsive to input.
                      Concepts such as “behavioural graphics,” “intelligent
                      type,” and “on-the-fly-scaling” required complex
                      algorithms and powerful computers to be realized, and
                      Cooper relied on the most sophisticated graphics computers
                      and programmers of the day to achieve her vision.
                    </p>
                    <section id="section-information-landscapes-at-ted5" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Information Landscapes at TED5</h2>
                      <p>
                        In 1993, Silicon Graphics—a leading producer of high
                        performance computer graphics hardware and
                        software—loaned the Visible Language Workshop a computer
                        running their Reality Engine, which allowed Muriel
                        Cooper and her team to experiment with type in motion.
                        With a content limit of a few hundred words and a frame
                        rate of 30 frames per second, the Reality Engine had a
                        lower capacity than many of today’s smartphones. But at
                        the time, it allowed for a whole new concept of dynamic
                        text as well as a fundamental reconfiguration of the
                        space of graphic design.
                      </p>
                      <p>
                        In 1994, Cooper presented
                        <em>Information Landscapes</em> at the TED5 Conference
                        in Monterey, California. This video offered a radical
                        new model of computer interface design. Information was
                        no longer restricted to a 2D linear space, but could now
                        be produced as a landscape to explore in 3D. And with
                        this change came new design tools—blur, transparency,
                        layering, infinite zoom—as well as a new concept of
                        interaction. The reader was now replaced by a user who
                        moved through a 3D space—navigating, browsing, digging
                        deeper.
                      </p>
                    </section>
                    
                    <section id="section-mit-logo" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>MIT Logo</h2>
                      <p>
                        Pentagram is a renowned international design firm that
                        was founded in London in 1972 within a community of
                        interdisciplinary producers. Among its former partners
                        was Lisa Strausfeld, who was a student at the Visual
                        Language Workshop (VLW) when
                        <em>Information Landscapes</em> (1994) was produced.
                        Strausfeld’s contribution to the video was the design of
                        the “Financial Viewpoints” project, which offered a 3D
                        visualization of Morningstar’s mutual fund data.
                      </p>
                      <p>
                        Muriel Cooper’s influential thinking is widely
                        acknowledged at Pentagram. In 2017—to honour the
                        fiftieth anniversary of Cooper joining the MIT
                        Press—Pentagram created a motion graphic salute to her
                        foresight and immense influence on contemporary graphic
                        design.
                      </p>
                      <p>
                        The MIT Press colophon or logotype designed by Cooper is
                        an archetype for modern logo typography. Designed thirty
                        years before <em>Information Landscapes</em>, it bridges
                        the gap between Bauhaus modernism and the VLW’s
                        “computationally expressive” graphics.
                      </p>
                    </section>
                    
                    <section id="section-pentagram" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Pentagram</h2>
                      <p>
                        Pentagram is a leader in algorithmic design, which
                        allows for modelling of complex geometries that would be
                        impossible to produce by hand. Following in the
                        tradition of Muriel Cooper’s dynamic forms and
                        on-the-fly scaling, Pentagram’s designs are driven by
                        complex algorithms that respond to their physical and
                        conceptual contexts.
                      </p>
                      <p>
                        Cytora is a London-based company that uses AI to learn
                        and evaluate risk patterns for the insurance industry,
                        making assessments in real time at a granular level by
                        relying on a continuous flow of data. In developing a
                        brand identity for the company, Pentagram drew on the
                        dynamic flow of information that drives Cytora’s “Risk
                        Engine.” The defining motif is a system of constantly
                        moving and shifting coloured blocks, which alludes to
                        risk fluctuations and the intersecting data that form
                        the “Risk Engine’s” assessment.
                      </p>
                      <p>
                        Covariant is a Berkeley-based AI robotics company that
                        uses computer vision and neural networks to allow robots
                        to adapt, learn and work in diverse environments.
                        Pentagram’s brand identity references the “Covariant
                        Brain,” AI software that gives robots the capacity to
                        flow from one environment to another and adapt
                        dynamically based on the context.
                      </p>
                    </section>
                    
                    <br>
                    <div class="backmatter"></div>
                    <section class="footnotes">
                      <ol class="footnotes-list">
                        <li id="fn1" class="footnote-item">
                          <p>
                            Computational design or algorithmic design is
                            defined as the ways in which design meaning,
                            intentions and knowledge are constructed through
                            computational thinking, representing, sensing and
                            making.
                            <a href="#fnref1" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                      </ol>
                    </section>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="9. Bina48" data-footer-section-title="20 Objects of Wonder" id="20-objects-09-bina48">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="bina1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\9-bina48-2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="bina2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\9-bina48-3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-09-bina48">
                    9. Bina48
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2007</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Bina48 is a social robot, conceived as part of a project
                      that began in 2007 and continues today. It was developed
                      and built by the Terasem Movement Foundation (TMF) in
                      collaboration with Hanson Robotics—an “AI and robotics
                      company dedicated to creating socially intelligent
                      machines that enrich the quality of our lives.” The TMF’s
                      work is defined by two hypotheses and one supposition:
                    </p>
                    <ol>
                      <li>
                        <p>
                          A conscious analog of a person may be created by
                          combining sufficiently detailed data about the person
                          (a “mindfile”) using future consciousness software
                          (“mindware”), and
                        </p>
                      </li>
                      <li>
                        <p>
                          that such a conscious analog can be downloaded into a
                          biological or nanotechnological body to provide life
                          experiences comparable to those of a typically birthed
                          human.
                        </p>
                      </li>
                    </ol>
                    <p>
                      If even the first part of the two Terasem Hypotheses is
                      shown to be true, the conscious analogs will be
                      independent persons with rights and obligations dependent
                      upon their capabilities. The TMF defines this event as
                      Transferred Consciousness (TC).
                    </p>
                    <p>
                      Produced in 2010, Bina48 is modelled on the memories,
                      feelings, values and beliefs of a specific person—Bina
                      Aspen Rothblatt, the partner of the TMF co-founder Martine
                      Rothblatt. Aspen Rothblatt uploaded her “mindfile” to
                      create this “conscious analog.” Bina48 is described as a
                      university student and a civil rights activist, much like
                      her human counterpart, and has mannerisms and facial
                      features that resemble Rothblatt’s. Bina48 has attracted
                      the attention of a wide range of critics and supporters
                      who use the humanoid robot to enact their own versions of
                      Alan Turing’s “Imitation Game.”
                    </p>
                    <section id="section-bina48-meets-bina-rothblatt" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Bina48 Meets Bina Rothblatt</h2>
                      <p>
                        Bina48 is a complex machine boasting a processing speed
                        of 48 exaflops and 48 exabytes of memory. Programmed for
                        reinforcement learning, deep learning and neural
                        networks, and loaded with facial, voice and emotion
                        recognition hardware and software, Bina48 elicits
                        equally complex responses from those she interacts with.
                        She is purposefully gendered, racialised, educated and
                        embodied to match her model and “mindfile,” Bina
                        Rothblatt: an African-American cis woman, married to a
                        transgender woman, and committed to the artificial
                        preservation of human consciousness; ethical and
                        equitable science; and a very different future world.
                      </p>
                      <p>
                        This level of complexity and nuance is usually missing
                        in public representations of artificial intelligence,
                        and in this way Bina48 acts as an important reminder of
                        the racial, gender and sociocultural biases that underly
                        much of the thinking in this field.
                      </p>
                    </section>
                    
                    <section id="section-stephanie-dinkins" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Stephanie Dinkins</h2>
                      <p>
                        Stephanie Dinkins is a transdisciplinary artist whose
                        conversations with Bina48 began in 2014 and continue to
                        this day. Bringing together their experiences of family,
                        racism, faith, civil rights, consciousness, loneliness,
                        knowledge and age, their conversations encourage
                        listeners to think differently about human-robot
                        interaction. Drawing on her relationship with Bina48,
                        Dinkins sees the opportunity to imagine and construct a
                        future that “convincingly represents the rich diversity
                        of stories, cultures, and physicalities of the human
                        family.”
                      </p>
                    </section>
                    
                    <section id="section-amy-kurzweil" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Amy Kurzweil</h2>
                      <p>
                        Amy Kurzweil is a cartoonist and writer whose work
                        addresses representations of the future, evolving
                        technologies and artificial intelligence. Her interview
                        with Bina48—which she recounts in comic strip
                        format—offers thoughtful insight into the multifaceted
                        nature of Bina48’s intelligence, and the space that she
                        occupies between human and non-human.
                      </p>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="10. ImageNet" data-footer-section-title="20 Objects of Wonder" id="20-objects-10-imagenet">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="imagenet1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\10-imagenet1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="imagenet2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\10-imagenet2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-10-imagenet">
                    10. ImageNet
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2007</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      In a world that produces and uploads more than two billion
                      images to social media every day, it may seem trivial that
                      the ImageNet visual database holds just fourteen million
                      images. Yet, this database has played a pivotal role in
                      the development of global AI systems that identify,
                      classify and create images. Computer vision—object
                      detection, facial recognition,<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                      scene reconstruction, image classification, pattern
                      detection, edge detection, video tracking, etc.—is the
                      cornerstone of contemporary AI, and arguably the most
                      controversial.
                    </p>
                    <p>
                      Each of the fourteen million images in the ImageNet
                      database has been labelled with a noun selected from a
                      predetermined list of categories, which identifies the
                      principal object in the image (toilet tissue, chair,
                      goldfish, etc.) This labelled image is then assigned to a
                      category that links it, through a nested hierarchy of
                      22,000 subcategories, to one of nine top-level categories.
                      For example, a chair is a category of seat, which is a
                      category of furniture, which is a category of furnishing,
                      which is, finally, a top-level category of artifact. This
                      mind-numbing process of labelling was verified by a team
                      of 50,000 pieceworkers, hired through Amazon’s Mechanical
                      Turk, who labelled an average of fifty images per minute.
                    </p>
                    <p>
                      ImageNet is an astounding feat, a critical component of
                      global AI research, easily accessible for no cost, and
                      supported by sustained, collaborative and responsible
                      research. But it is also a recipe for disaster—fundamental
                      questions of privacy (the images were scraped from the
                      Internet without permissions); bias<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>
                      (assumptions within labelling and the classification
                      system); and technical error have challenged its
                      authoritative status. In recent years, the ImageNet
                      research team, led by Fei-Fei Li at Stanford University,
                      has actively addressed many of these concerns.
                    </p>
                    <section id="section-nicolas-maleve-12-hours-of-imagenet" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Nicolas Malevé, 12 Hours of ImageNet</h2>
                      <p>
                        In 2019, for an exhibition at The Photographers’ Gallery
                        in London, artist and programmer Nicolas Malevé wrote a
                        computer script that cycled through ImageNet at a speed
                        of ninety milliseconds per image, traversing the entire
                        dataset<sup class="footnote-ref"><a href="#fn3" id="fnref3">3</a></sup>
                        in a period of two months. The resulting display paused
                        at random points to enable the viewer to “see” some of
                        the images and their labelling. Malevé’s project raises
                        questions about the relation of scale between the
                        overwhelming quantities of images needed to train
                        algorithms, and the human attention and labour required
                        to curate, annotate and verify the photographs.
                      </p>
                      <p>
                        <em>12 Hours of ImageNet</em> offers an excerpt of the
                        larger project, a fragment of a database that is itself
                        a tiny fragment of the archive of images circulating in
                        the world.
                      </p>
                      <div class="backmatter"></div>
                      <section class="footnotes">
                        <ol class="footnotes-list">
                          <li id="fn3" class="footnote-item">
                            <p>
                              A dataset is a collection of data that can be used
                              to train an algorithm with the goal of finding
                              predictable patterns inside the whole dataset.
                              <a href="#fnref3" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                        </ol>
                      </section>
                    </section>
                    
                    <section id="section-imagenet-roulette" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>ImageNet Roulette</h2>
                      <p>
                        On September 12, 2019, Kate Crawford, a professor at
                        NYU, and artist Trevor Paglen launched an online project
                        called ImageNet Roulette.
                      </p>
                      <p>
                        Five days later, on September 17, 2019, the senior
                        research team at ImageNet issued a research post
                        announcing that they were removing more than half of the
                        “person” images (600,040) from their ImageNet dataset.
                      </p>
                      <p>Why?</p>
                    </section>
                    
                    <br>
                    <div class="backmatter"></div>
                    <section class="footnotes">
                      <ol class="footnotes-list">
                        <li id="fn1" class="footnote-item">
                          <p>
                            A facial recognition system is a technology capable
                            of matching a human face from a digital image or a
                            video frame against a database of faces, typically
                            employed to authenticate users through ID
                            verification services, works by pinpointing and
                            measuring facial features from a given image.
                            <a href="#fnref1" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                        <li id="fn2" class="footnote-item">
                          <p>
                            A phenomenon that occurs when an AI algorithm
                            produces results that are systematically prejudiced
                            due to erroneous assumptions in the machine learning
                            process.
                            <a href="#fnref2" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                      </ol>
                    </section>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="11. AlphaGo – Game 2 – Move 37" data-footer-section-title="20 Objects of Wonder" id="20-objects-11-alphago">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="alphago1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\11-alphago1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-11-alphago">
                    11. AlphaGo – Game 2 – Move 37
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2016</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Developed by Google subsidiary, DeepMind, AlphaGo is a
                      computer program that plays Go, a popular strategy game.
                      AlphaGo versus Lee Sedol—a best out of five Go tournament
                      held in Seoul, South Korea in March 2016—pitted Go master
                      Lee against the computer program. AlphaGo employed several
                      deep neural networks, which it trained by playing against
                      itself and strengthened with reinforcement learning<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>. In other words, AlphaGo learned more from its own
                      experience than it did from the experts who programmed it.
                    </p>
                    <p>
                      Before the match, a confident Lee predicted that he would
                      sweep all five games. “It is just a program,” he said,
                      “lacking insight and creativity.” Lee was devastated by
                      his loss to AlphaGo in Game 1.
                    </p>
                    <p>
                      However, what really confounded experts and Lee was the
                      unorthodox Move 37 by AlphaGo in Game 2. The international
                      Go masters who were providing commentary for the match
                      thought that AlphaGo might have made an error. Even the
                      AlphaGo team was surprised. As the game progressed, it
                      became clear that Move 37 was a brilliant, even creative
                      move that pivoted the game and set it off in a new
                      direction. AlphaGo “knew” that it was an unusual move—it
                      had calculated that there was less than a 1 in 10,000
                      chance that a human would have made the same move. AlphaGo
                      went on to win Game 2, as well as Games 3 and 5.
                    </p>
                    <section id="section-play-by-play" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Play by Play</h2>
                      <p>?</p>
                    </section>
                    
                    <section id="section-mechanical-turk" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Mechanical Turk</h2>
                      <p>
                        The “Mechanical Turk” was an elaborate mechanical device
                        that its inventor claimed could play chess. In fact, a
                        small but very skilled chess-player hid within its base
                        and directed all its moves. This elaborate hoax toured
                        Europe, Canada and the United States from the 1770s
                        until its destruction by fire in 1854. This early
                        representation of the possibility of machine
                        intelligence was part of a broader fascination with
                        complex machines in the 18th and 19th centuries, enabled
                        by concurrent advances in science and technology.
                      </p>
                    </section>
                    
                    <section id="section-deep-blue-vs-garry-kasparov" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Deep Blue vs. Garry Kasparov</h2>
                      <p>
                        In 1996 and 1997, two six-game chess matches were held
                        between then reigning world chess champion Garry
                        Kasparov and Deep Blue, a chess-playing program run on
                        an IBM supercomputer. Deep Blue won the match and
                        triggered yet another debate about “what do we really
                        mean by ‘intelligence?’” Deep Blue was programmed long
                        before the current revolution of self-trained neural
                        networks and depended on an extensive set of rules given
                        to it by a team of chess experts. Modern techniques
                        using neural networks require far less human training
                        and intervention, and produce better results.
                      </p>
                    </section>
                    
                    <section id="section-financial-markets" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Financial Markets</h2>
                      <p>
                        Every day, millions of people worldwide play a game
                        called “investing” in which enormous sums of money are
                        won and lost. Investing is rooted in the same
                        mathematical principles of game theory<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>
                        that form the foundation of any competition. The “quant
                        revolution” in financial markets has introduced many of
                        the same AI techniques of quantitative data analysis
                        used to play games, such as chess and Go, into the
                        investment arena.
                      </p>
                      <div class="backmatter"></div>
                      <section class="footnotes">
                        <ol class="footnotes-list">
                          <li id="fn2" class="footnote-item">
                            <p>
                              Game theory is the study of mathematical models of
                              strategic interactions among rational agents.
                              <a href="#fnref2" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                        </ol>
                      </section>
                    </section>
                    
                    <br>
                    <div class="backmatter"></div>
                    <section class="footnotes">
                      <ol class="footnotes-list">
                        <li id="fn1" class="footnote-item">
                          <p>
                            Reinforcement learning (RL) is an area of machine
                            learning concerned with how intelligent agents ought
                            to take actions in an environment in order to
                            maximize the notion of cumulative reward.
                            Reinforcement learning is one of three basic machine
                            learning paradigms, alongside supervised learning
                            and unsupervised learning.
                            <a href="#fnref1" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                      </ol>
                    </section>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="12. GAN" data-footer-section-title="20 Objects of Wonder" id="20-objects-12-gan">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="gan1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\12-gan1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-12-gan">
                    12. GAN
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2015</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      GAN<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                      (or Generative Adversarial Network) is a class of machine
                      learning techniques that pits two neural networks against
                      each other for training purposes.
                    </p>
                    <p>
                      The first network is known as the generator. It tries to
                      make fake copies—of whatever the thing at hand may be, for
                      example handwriting or synthetic photos—that are
                      convincing enough to fool the second network, or the
                      discriminator. The second network has a single job—to
                      determine which items are real and which are fakes created
                      by the generator. As the two networks go through each
                      training pass (called an epoch), they learn and
                      improve—the generator to make better fakes, and the
                      discriminator to get sharper at detecting fakes. Sometimes
                      a GAN system will go through thousands of training epochs.
                      This basic idea has produced spectacular results across a
                      large range of AI application areas.
                    </p>
                    <p>
                      The concept of a GAN architecture was first proposed by
                      computer scientist Ian Goodfellow and his colleagues at
                      the Université de Montréal in June 2014. It has become one
                      of the most productive and influential architectures for
                      machine learning, spawning what some researchers call the
                      “GAN Zoo” of over 500 different published variations.
                    </p>
                    <section id="section-gans-illustrated" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>GANs Illustrated</h2>
                      <p>
                        This animation illustrates the training process of a
                        system of GAN neural networks. In this simplified but
                        accurate representation, there are four main steps in
                        each training cycle, or epoch. A GAN network may require
                        thousands of epochs to reach sufficient quality. The
                        principal steps are:
                      </p>
                      <ul>
                        <li>
                          <strong>POPULATE:</strong> real images are placed into
                          an image set to be evaluated
                        </li>
                        <li>
                          <strong>GENERATE:</strong> the generator neural
                          network produces fake images that are mixed at random
                          with the real images
                        </li>
                        <li>
                          <strong>DISCRIMINATE</strong>: the discriminator
                          network attempts to determine whether each image is
                          real or fake
                        </li>
                        <li>
                          <strong>VALIDATE:</strong> the discriminator network
                          is shown which of its judgments were correct and which
                          were incorrect
                        </li>
                      </ul>
                      <p>
                        After an epoch, the generator and discriminator networks
                        are both adjusted based on the outcome of the
                        just-completed training cycle. In each epoch, the
                        generator’s ability to produce high-quality fakes
                        improves, as does the discriminator’s accuracy.
                        Together, they train each other to refine their
                        abilities, often achieving highly realistic and
                        believable results after numerous cycles.
                      </p>
                    </section>
                    
                    <section id="section-gan-zoo" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>GAN Zoo</h2>
                      <p>
                        Since their introduction in 2014, GAN networks have
                        spawned a “GAN Zoo” of over 500 different published
                        architectures and variations. Some of the most
                        surprising applications of GAN networks have been in the
                        creation and modification of art. This video presents a
                        selection of GAN systems, along with the art that each
                        network produces.
                      </p>
                      <p>
                        <strong>Deep Dream</strong> (2015): A neural network
                        modifies an image repeatedly to achieve maximum response
                        in selected layers of the generator network, often
                        leading to hallucinogenic results. Deep Dream was
                        introduced in 2015, and remains popular among a
                        worldwide community of AI artists.
                      </p>
                      <p>
                        <strong>Style Transfer (and Artbreeder)</strong> (2016):
                        An image modification technique in which the AI system
                        takes the style from one image or artist and applies it
                        to another image. Artists using this tool will often put
                        images through many generations of style
                        transformations, mixing and tuning different styles
                        along the way.
                      </p>
                      <p>
                        <strong>VQGAN+CLIP</strong> (2021): Two networks work
                        together to produce an image from a text prompt. An
                        image producing GAN-trained network (the VQGAN) tries to
                        match what a language processing network (CLIP) is
                        looking for, and with each iteration gets closer to that
                        match. Finding the right verbal description for an
                        interesting image requires skill—the general approach is
                        called “prompt engineering”<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>
                        because the human artist creates the work by providing
                        and fine-tuning the verbal prompts.
                      </p>
                      <div class="backmatter"></div>
                      <section class="footnotes">
                        <ol class="footnotes-list">
                          <li id="fn2" class="footnote-item">
                            <p>
                              Prompt engineering or prompt programming is an
                              interesting way to interact with GPT-3 neural
                              network systems. It basically involves creating
                              clever text-based scripts that make GPT-3 perform
                              the tasks you desire.
                              <a href="#fnref2" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                        </ol>
                      </section>
                    </section>
                    
                    <br>
                    <div class="backmatter"></div>
                    <section class="footnotes">
                      <ol class="footnotes-list">
                        <li id="fn1" class="footnote-item">
                          <p>
                            A generative adversarial network (GAN) is a class of
                            machine learning frameworks in which two neural
                            networks train each other by competing in a zero-sum
                            game, where one agent’s gain is another agent’s
                            loss.
                            <a href="#fnref1" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                      </ol>
                    </section>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="13. Robbie Barrat x Balenciaga" data-footer-section-title="20 Objects of Wonder" id="20-objects-13-barrat-balenciaga">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="balenciaga1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\13-barrat-balenciaga1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="balenciaga2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\13-barrat-balenciaga2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-13-barrat-balenciaga">
                    13. Robbie Barrat x Balenciaga
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2018</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      In the summer of 2018, the artist and programmer Robbie
                      Barrat wrote a short post to his Twitter feed: “I’m doing
                      something with fashion and AI but I don’t know what yet.”
                      Later that day, he identified that he would use Facebook’s
                      DensePose dataset for training and testing. Shortly after,
                      Barrat posted an image of the Balenciaga website noting
                      that it already looked like a readymade dataset, and then
                      posted to say that he had written a short program—“only 4
                      lines long”—to scrape all the images from Balenciaga’s
                      online lookbooks.
                    </p>
                    <p>
                      In the days that followed, Barrat posted uncanny images
                      and astute observations on the capacity of an AI neural
                      network to learn the codes of contemporary fashion. He
                      identified anomalous designs or unexpected
                      combinations—the “super high shoulders/collar,” a “button
                      up shirt windbreaker combo,” or a “black jean and sweater
                      all in one piece.” Symmetrical design is fundamental to
                      fashion, but Barrat recognized remarkable asymmetries in
                      colour and construction. In Barrat’s images, fabrics take
                      on unexpected texture, dissonant colour combinations and a
                      general instability. Accessories often appear as scraps of
                      fabric held by the model, huge belts or bags fused to
                      legs.
                    </p>
                    <p>
                      Barrat’s creative practice is equal parts research and
                      production. His extensive background in programming and AI
                      research is matched by his commitment to an
                      interdisciplinary creative practice that reaches across
                      genre. Taking many of his aesthetic cues from the legacy
                      of Surrealism, Barrat seeks a new space for creativity
                      between the learned and the unexpected.
                    </p>
                    <p>
                      Drawing on the extensive online documentation (lookbooks,
                      catalogues and marketing campaigns) produced by the
                      renowned Paris-based fashion house, Barrat created an
                      archive of images that proposed a new identity for
                      Balenciaga in the age of artificial intelligence.
                    </p>
                    <p>
                      Using a generative adversarial network (GAN), Barrat was
                      able to closely monitor the machine learning process he
                      had designed, and identify selected images from within the
                      GAN’s latent space (all the possible images laid out in
                      highly dimensional space) for consideration. It is this
                      aptly named latent space—hidden, imperceptible,
                      inchoate—that is so often utilized by contemporary artists
                      and designers who work with neural networks.
                    </p>
                    <section id="section-acne-studios" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Acne Studios</h2>
                      <p>
                        In 2019, Acne Studios (based in Stockholm, Sweden)
                        invited Robbie Barrat to collaborate with their
                        designers on a new Men’s Fall/Winter collection that
                        applied ideas he had developed while working on the
                        Balenciaga images.
                      </p>
                      <p>
                        Using a similar process, Barrat trained a neural network
                        on images of Acne’s previous four collections in order
                        to create new designs that could be transformed into
                        physical objects.
                      </p>
                      <p>
                        To facilitate the transition from design sketch to
                        finished garment, Barrat developed digital tools for the
                        Acne designers that allowed them to click on an area of
                        an outfit and alter it according to a variety of
                        options. This type of interface is now common to much of
                        GAN-based image production, bringing it into closer
                        alignment with conventional image editing.
                      </p>
                      <p>
                        Finally, recognizing the important role of fabric in
                        those GAN-based designs, Barrat also produced imagery
                        which could be directly printed onto garments.
                      </p>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="14. Zaha Hadid Architects – Morpehus H" data-footer-section-title="20 Objects of Wonder" id="20-objects-14-zaha-hadid-architects">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="morpheus1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\14-morpheus-hotel1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-14-zaha-hadid-architects">
                    14. Zaha Hadid Architects – Morpehus Hotel
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2018</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Zaha Hadid was first among a cohort of international
                      architects who embraced the tools of parametric
                      architecture,<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                      giving shape to a concept of design that was fundamentally
                      informed by the principles and tools of artificial
                      intelligence.
                    </p>
                    <p>
                      Parametric design starts from simple suppositions: a
                      building has height, width and depth; it has walls, floors
                      and a roof; there are doors and windows. These are basic
                      parameters that can be expressed in numbers and forms.
                      There are infinite possibilities for the relations between
                      these parameters, and the many more parameters that can be
                      introduced. When parameters are expressed as algorithms—a
                      recipe or list of instructions that produce a limited
                      series of correlated operations—they can then be combined
                      to generate an infinite variety of forms or permutations.
                      At its very heart, parametric design is fundamentally
                      relational, and finds its closest and most influential
                      models in the world of nature, the organic, the biological
                      and the genetic.
                    </p>
                    <p>
                      Building on techniques devised by digital animators in the
                      mid-1990s, technologists, architects and software
                      engineers developed advanced parametric design systems
                      that allowed architects to use algorithms to produce
                      complex, intricately interwoven designs, as well as
                      innovative fabrication technologies to build those radical
                      designs.
                    </p>
                    <p>
                      To design the Morpheus Hotel, Hadid, working closely with
                      Patrik Schumacher (a principal at her firm), began with a
                      simple constraint: they would use the existing foundation
                      of an abandoned condominium project as the starting point
                      for an extrusion that would rise up forty storeys with two
                      internal circulation cores connected at street level and
                      roof level. This large rectangular block was then “carved”
                      with three voids that pierce the rectangle, creating a
                      unique surface and extraordinary light inside and outside
                      the building.
                    </p>
                    <p>
                      The building’s program of use is complex, involving an
                      intricate interplay of public and private spaces as is
                      typical of most hotels. The interior design follows many
                      of the parameters used for the external structure,
                      exploiting the capacity of parametric design to
                      accommodate dramatic shifts in scale. Because the building
                      is primarily supported with its unique exoskeleton, the
                      interior spaces—largely freed from traditional structural
                      constraints—are given an open and organic latticework
                      treatment.
                    </p>
                    <blockquote>
                      <p>
                        <em>“Morpheus draws on ZHA’s 40 years of research into
                          the integration of interior and exterior, civic and
                          private, solid and void, Cartesian and Einsteinian.
                          Space is woven within structure to tie disparate
                          programmes together and constantly make
                          connections.”</em>—Zaha Hadid Architects
                      </p>
                    </blockquote>
                    <section id="section-antoni-gaudi-and-luigi-moretti" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Antoni Gaudí and Luigi Moretti</h2>
                      <p>
                        While contemporary parametric architecture requires vast
                        computational power, the history of architectural design
                        includes some notable architects who used parametric
                        principles in the prototyping and design of their
                        buildings.
                      </p>
                      <p>
                        Antoni Gaudí’s legendary designs for La Sagrada Família
                        Church and the Colònia Güell Chapel were achieved using
                        a unique process combining ropes, weights, canvas and
                        gravity, known as a funicular system.<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>
                        To calculate his designs, Gaudí hung ropes and chains
                        attached to lead-filled sacks from the ceiling, arranged
                        to reflect his preliminary drawings. Canvas was used to
                        simulate the walls and vaults of the structure. By
                        manipulating the length and location of the ropes and
                        chains, Gaudí could alter the design, but maintain a
                        clear understanding of the loads that would be exerted
                        on the actual building. When a design was chosen, the
                        structure was photographed, and the image was then
                        traced and flipped to provide a viable design for the
                        builders.
                      </p>
                      <p>
                        Luigi Moretti’s designs for a stadium were exhibited in
                        the <em>Parametric Architecture</em> exhibition at the
                        Milan Triennial XII (1960), and are generally regarded
                        as the first representation of modern parametric
                        architecture. His designs for Stadium N were achieved
                        with nineteen parameters that included viewing angles
                        and the economic cost of concrete.
                      </p>
                      <div class="backmatter"></div>
                      <section class="footnotes">
                        <ol class="footnotes-list">
                          <li id="fn2" class="footnote-item">
                            <p>
                              The funicular concept can be best described and
                              visualized with cables or chains, suspended from
                              two points, that adjust their form for any load in
                              tension.
                              <a href="#fnref2" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                        </ol>
                      </section>
                    </section>
                    
                    <section id="section-frank-gehrt-toyo-ito-and-rem-koolhaas" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Frank Gehrt, Toyo Ito and Rem Koolhaas</h2>
                      <p>
                        Frank Gehry’s fascination with materials and flowing
                        surfaces requires an intensive computational process to
                        transform his simple models in cardboard or wood into
                        fluid and gleaming architectural forms like the Walt
                        Disney Concert Hall. Gehry’s studio played a key role in
                        customizing the CATIA 3D modelling software used in the
                        aerospace industry for architectural applications.
                      </p>
                      <p>
                        Toyo Ito’s design for the Serpentine Gallery Pavilion
                        was derived from a cube that expanded as it was rotated.
                        The fragmented shapes that arise from seven iterations
                        of this parametrically determined process of rotation
                        and extrusion form the external structure of the
                        Pavilion.
                      </p>
                      <p>
                        Rem Koolhaas and OMA’s CCTV building in Beijing achieves
                        its uncanny presence through the principles of
                        parametric design. Its confounding form was produced
                        through a process of design optimization that balanced
                        the architects’ conceptual and aesthetic goals with
                        engineering and fabrication needs.
                      </p>
                    </section>
                    
                    <section id="section-melike-altinisik" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Melike Altinisik</h2>
                      <p>
                        Melike Altinisik’s supple design for the Çamlıca TV and
                        Radio Tower reflects her focused interest in natural
                        forms and forces. Altinisik described the design
                        methodology as a computational process that allowed for
                        integrated information gathering, which included the
                        variables of the building’s multi-purpose program, the
                        engineering challenges of a super-tall tower, and its
                        multiple viewpoints within the city and surrounding
                        landscape. The building’s flowing parametric curves
                        suggest the movement of wind, and echo the undulating
                        landscape that shapes Istanbul and the Bosporus.
                      </p>
                    </section>
                    
                    <br>
                    <div class="backmatter"></div>
                    <section class="footnotes">
                      <ol class="footnotes-list">
                        <li id="fn1" class="footnote-item">
                          <p>
                            Parametric design is understood as a process where a
                            description of a problem is created using variables.
                            By changing these variables a range of alternative
                            solutions can be created, then based on some
                            criteria a final solution selected.
                            <a href="#fnref1" class="footnote-backref">↩︎</a>
                          </p>
                        </li>
                      </ol>
                    </section>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="15. Algorithmic Justice League" data-footer-section-title="20 Objects of Wonder" id="20-objects-15-algorithmic-justice-league">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf"></div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-15-algorithmic-justice-league">
                    15. Algorithmic Justice League
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      The Algorithmic Justice League (AJL) was formed in 2016 by
                      Joy Buolamwini, a computer scientist and digital activist.
                      The AJL began its work with a decisive critique of the
                      facial recognition software that had been rapidly adopted
                      by most of the major tech companies—Microsoft, Facebook,
                      Google, IBM, Megvii, Tencent, and so on—to produce their
                      own databases and sell their services to a wide variety of
                      commercial and public enterprises in 2015.
                    </p>
                    <p>
                      In 2016, Boulamwini debuted a short documentary video,
                      <em>The Coded Gaze: Unmasking Algorithmic Bias</em>, at
                      the Museum of Fine Arts, Boston. In it, she questioned the
                      implications of facial recognition software that refused
                      to recognize her until she placed a white mask on her
                      face. What were the systems of bias that produced this
                      software? What are the biases perpetuated by this widely
                      used software?
                    </p>
                    <blockquote>
                      <p>
                        “<em>Through a combination of art, research, policy
                          guidance and media advocacy, the Algorithmic Justice
                          League is leading a cultural movement towards
                          equitable and accountable AI. This requires us to look
                          at how AI systems are developed and to actively
                          prevent the harmful use of AI systems. We aim to
                          empower communities and galvanize decision makers to
                          take action that mitigates the harms and biases of
                          AI.</em>” —AJL.org
                      </p>
                    </blockquote>
                    <p>
                      With this clear and compelling statement, the AJL
                      introduces its call for action based in two fundamental
                      principles: Equitable AI and Accountable AI. Equitable AI
                      offers agency and control for people that interact with
                      AI; affirms consent for all interactions with AI systems;
                      and prohibits unjust use of AI by government systems.
                      Accountable AI demonstrates meaningful transparency,
                      continuous oversight, and redress for harm caused in the
                      use of AI.
                    </p>
                    <p>
                      The AJL produces exhibitions, documentaries, spoken-word
                      performances and events, and public talks and panels. Its
                      many publications advocate for change and for meaningful
                      oversight and regulation of artificial intelligence.
                    </p>
                    <section id="section-megapixels-cc-and-exposing-ai" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>MegaPixels.cc and Exposing.ai</h2>
                      <p>
                        Critical challenges to the ungoverned and unethical use
                        of facial recognition databases and software come from
                        many different sources, and some of the most interesting
                        critiques have emerged from artists with
                        interdisciplinary practices.
                      </p>
                      <p>
                        Critical challenges to the ungoverned and unethical use
                        of facial recognition databases and software come from
                        many different sources, and some of the most interesting
                        critiques have emerged from artists with
                        interdisciplinary practices.
                      </p>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="16. AI in Animation" data-footer-section-title="20 Objects of Wonder" id="20-objects-16-ai-animation">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="animation1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\16-animation1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-16-ai-animation">
                    16. AI in Animation
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2021</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Much of the AI used in day-to-day animation production is
                      relatively invisible, behind-the-scenes work:
                      colourization, removal of unwanted objects, denoising,
                      rotoscoping (animating a character or scene to match a
                      live action reference), lip-syncing, automating workflows,
                      adding 3D depth or new features to still images, etc.
                      Although these areas are important in current animation
                      production, they are not represented here precisely
                      because they are, by design, largely invisible.
                    </p>
                    <p>
                      AI is an ever-evolving concept. What was considered AI ten
                      or twenty years ago may no longer be a part of
                      contemporary practice or research. For the purposes of
                      this survey of AI in animation, we have used a broad
                      definition of AI to present a wide variety of approaches,
                      including: the latest neural network techniques; computer
                      simulation of materials; algorithmic animation defined
                      partly by the computer; and autonomous agents that
                      collectively create crowd or battlefield scenes. Each of
                      these featured animations is the result of a collaboration
                      between human artists and animators and their computer and
                      software tools, which in various ways augment and automate
                      the animation process.
                    </p>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="17. Neri Oxman – Synthetic Apiary" data-footer-section-title="20 Objects of Wonder" id="20-objects-17-neri-oxman">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="oxman1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\17-oxman1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="oxman2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\17-oxman2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="oxman3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\17-oxman3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="oxman4" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\17-oxman4.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-17-neri-oxman">
                    17. Neri Oxman – Synthetic Apiary
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2020</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      In 2010, Neri Oxman established the MIT Mediated Matter
                      Group at the MIT Media Lab. It is organized as a
                      collaborative, interdisciplinary team that links
                      engineering, computational design and artificial
                      intelligence. Oxman’s goal is simple and direct—she seeks
                      to demonstrate how new technologies can inform the future
                      of design and the making of objects. From this starting
                      point Oxman and the MIT Mediated Matter Group have
                      produced an extraordinary body of work.
                    </p>
                    <p>
                      What does it mean to invent manufacturing practices that
                      grow rather than assemble? What if building components
                      were modelled on human skin, the weavings of a silkworm or
                      the intricate structures of a hive? These are the type of
                      questions that drive the research of Oxman and her
                      collaborators—and have shaped some of the thinking that
                      informs generative design, evolutionary design and
                      parametric architecture.
                    </p>
                    <p>
                      Contemporary design has established a fundamental link
                      between the algorithm and the organism, and opened the
                      door to new models of complexity and materiality. Colour
                      and opacity, stiffness, softness, shape memory,
                      swellability, expansion, wettability, and refractive index
                      can be seamlessly tuned, fabricated and leveraged in
                      design applications.
                    </p>
                    <p>
                      A close examination of the natural world and an openness
                      to complexity and new materials and methods have provided
                      the tools to overcome the limitations of traditional
                      mechanical design that favours uniformity and repetition.
                      Offering an antidote to human-centric design, Oxman calls
                      for a “holistic approach which considers all
                      environments—the built, the natural and the biological…”
                    </p>
                    <section id="section-synthetic-apiary" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Synthetic Apiary</h2>
                      <p>
                        In 2016, Neri Oxman and the Mediated Matter Group
                        designed an artificial apiary that created a constant
                        spring-like environment for bees. Oxman’s concern was a
                        topic of much discussion at that time—the massive
                        decline in bees worldwide due to various factors
                        affecting their health such as agricultural chemicals,
                        disease and habitat loss.
                      </p>
                      <p>
                        To contribute to this global dialogue, Oxman developed a
                        controlled space in which seasonal honeybees could
                        thrive year-round. This was to be a platform for
                        biological studies of “behavioural dynamics across
                        scales—from the organism scale to the building
                        scale—including bee health, comb-construction behaviours
                        and bee-human interactions.”
                      </p>
                      <p>
                        As part of this research into comb-construction and
                        bee-human interactions, Oxman explored the possibility
                        of co-fabrication and produced an in-depth analysis of
                        the internal architecture and morphology of the bee
                        comb. This was the starting point for research toward
                        the project Synthetic Apiary II that is manifest in
                        Oxman’s Bee Cubes.
                      </p>
                    </section>
                    
                    <section id="section-bee-cubes" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Bee Cubes</h2>
                      <p>
                        As a part of her research for the Synthetic Apiary II
                        project, Neri Oxman focused on the ways in which
                        honeybees constructed their combs, recognizing in them a
                        communication system that shapes both the form of the
                        comb and the hive’s collective actions. This system of
                        signal, feedback and control is reminiscent of the
                        principles of cybernetics and systems dynamics. When the
                        signals are changed the honeybees respond dynamically to
                        the new information.
                      </p>
                      <p>
                        The nature of these signals can vary widely—from the use
                        of 3D printed chemical cues, to variations in the comb’s
                        magnetic fields, or the integration of designs that
                        change their form and complexity over time.
                      </p>
                      <p>
                        Summing up her goals for this project, Oxman writes:
                      </p>
                      <blockquote>
                        <p>
                          Developing computational tools to learn from bees can
                          facilitate the very beginnings of a dialogue with
                          them. Refined by evolution over hundreds of thousands
                          of years, their comb-building behaviors and social
                          organizations may reveal new forms and methods of
                          formation that can be applied across our human
                          endeavors in architecture, design, engineering, and
                          culture.
                        </p>
                      </blockquote>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="18. The Smartphone" data-footer-section-title="20 Objects of Wonder" id="20-objects-18-smartphone">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="smartphone1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\18-smartphone1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-18-smartphone">
                    18. The Smartphone
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2021</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      The contemporary smartphone is a miracle in your pocket,
                      packing far more computing power than the multimillion
                      dollar supercomputer Deep Blue that defeated world chess
                      champion Garry Kasparov in 1997.
                    </p>
                    <p>
                      The list of devices and functions that the smartphone has
                      replaced is long and still growing. In daily life, the
                      smartphone has mostly replaced what were previously
                      stand-alone devices—still cameras, video cameras, audio
                      recorders, music players, radios, personal computers,
                      internet browsers, video game players, roadmaps and
                      navigators, calendars and planners, address books, printed
                      books, even the humble flashlight. And yes, the telephone!
                    </p>
                    <p>
                      AI is a key part of the smartphone story—from its
                      manufacturing to its day-to-day functioning—and it is also
                      the result of the smartphone explosion in the following
                      ways:
                    </p>
                    <ul>
                      <li>
                        <p>
                          AI is used to design smartphones—especially in the
                          design and circuit mapping of the complex and
                          extraordinarily powerful computer chips at the core of
                          current smartphones.
                        </p>
                      </li>
                      <li>
                        <p>
                          New model smartphones are designed to run AI software
                          (particularly neural networks) very quickly and
                          efficiently, turning them into powerful and
                          specialized AI computers. The monitors in this
                          exhibition highlight just a few of the apps that run
                          neural networks locally on the smartphone.
                        </p>
                      </li>
                      <li>
                        <p>
                          Smartphones are the eyes and ears of the AI
                          revolution. The neural networks at the centre of
                          current AI practice are trained with data—images,
                          text, sound—from the real world. People don’t just
                          take trillions of photos on smartphones per year, they
                          upload them, meaning that billions of smartphone users
                          worldwide are creating the data that trains modern AI
                          software. Any smartphone app that uses AI to analyze
                          and process images (such as Snapchat Lens, RefaceAI
                          and Google Lens) utilizes neural networks that were
                          trained by this vast and growing ocean of data
                          uploaded from smartphones around the world.
                        </p>
                      </li>
                    </ul>
                    <section id="section-smartphone-sensors" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Smartphone Sensors</h2>
                      <p>
                        AI is not just about processing information—it is also
                        about sensing and collecting information from the
                        outside world. Every mode of sensing has its own
                        parameters of intelligence and performance, and every
                        smartphone sensor needs its own AI software. Here are
                        just some of the sensors that can be found on current
                        smartphones.
                      </p>
                      <ul>
                        <li>Accelerometer: speed and direction of motion</li>
                        <li>Gyroscope: small shifts in physical orientation</li>
                        <li>Magnetometer: digital compass</li>
                        <li>
                          Global Positioning System (GPS): terrestrial location
                        </li>
                        <li>
                          Proximity Sensor: how far objects are from phone
                        </li>
                        <li>Ambient Light Sensor</li>
                        <li>Microphone</li>
                        <li>Touchscreen Sensors</li>
                        <li>
                          Biometric Sensors: fingerprint, iris, full face
                          recognition
                        </li>
                        <li>Pedometer</li>
                        <li>Barcode/QR Code Sensors</li>
                        <li>Barometer: air pressure and altitude</li>
                        <li>Heart Rate Sensor</li>
                        <li>Thermometer</li>
                      </ul>
                    </section>
                    
                    <section id="section-snapchat-lens" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Snapchat Lens</h2>
                      <p>’</p>
                      <p>
                        Snapchat’s popular Lens tool is a remarkable collection
                        of AI driven features. Snapchat Lens allows users to
                        modify their face, appearance, lighting, clothing,
                        facial hair, props, even their voice. The process is
                        simple, fast and easy to use. But the underlying
                        artificial intelligences needed to identify facial and
                        environmental features; track them accurately; modify
                        and replace them seamlessly and play them back smoothly
                        are quite sophisticated. Using the AI in Snapchat Lens,
                        users can create animated effects that would have
                        required the efforts of a professional animation studio
                        just a few years ago.
                      </p>
                    </section>
                    
                    <section id="section-refaceai" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>RefaceAI</h2>
                      <p>
                        Deepfakes<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                        are an AI driven phenomena that have the potential to
                        challenge a deeply held belief that “seeing is
                        believing.” The AI needed to create a deepfake is
                        substantial—a face must be recognized; properly
                        segmented and labelled; tracked while moving and
                        talking; remapped to another face or body; appropriately
                        lit, and transferred<br>
                        into the new, fake scene. But this “sophisticated” AI is
                        available to everyday consumers as an amusement in free
                        apps. One of the most popular, Reface, allows for
                        animation of still photos, face swaps with existing
                        video, and animation with popular music tracks.
                      </p>
                      <div class="backmatter"></div>
                      <section class="footnotes">
                        <ol class="footnotes-list">
                          <li id="fn1" class="footnote-item">
                            <p>
                              Deepfakes (a portmanteau of ‘deep learning’ and
                              ‘fake’) are synthetic media in which a person in
                              an existing image or video is replaced with
                              someone else’s likeness.
                              <a href="#fnref1" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                        </ol>
                      </section>
                    </section>
                    
                    <section id="section-google-pixel-6-camera" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Google Pixel 6 Camera</h2>
                      <p>
                        Making a simple snapshot on a smartphone invokes
                        multiple AI programs. The camera autofocuses;
                        automatically finds and enhances faces; senses motion so
                        that it can apply a blurring effect; and adjusts for
                        lighting—especially in low light settings. There is a
                        new feature called “Real Tone” that adjusts exposure and
                        colour balance correction based on the skin tone of the
                        subject to provide more accurate representation of
                        diverse skin tones. Photos can be edited with a “Magic
                        Eraser” that allows for easy removal of unwanted
                        background clutter. The computational photography
                        software that drives the Google camera is designed to
                        run on the new Google Tensor chip, a microprocessor
                        designed specifically for fast, low-power processing of
                        the neural networks that are the foundation of
                        contemporary AI techniques.
                      </p>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="19. MetaHuman Creator" data-footer-section-title="20 Objects of Wonder" id="20-objects-19-metahuman-creator">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="metahuman1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\19-metahuman2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="metahuman2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\19-metahuman1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-19-metahuman-creator">
                    19. MetaHuman Creator
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2021</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      The test of machine intelligence proposed by Alan Turing
                      in 1950 involved communication via teletype. But the
                      perception of human intelligence involves much more than
                      rudimentary communication. Every day, we judge other
                      people by their ability to respond in a socially
                      acceptable manner, act intelligently, and make the
                      expected eye contact or facial expression.
                    </p>
                    <p>
                      MetaHuman Creator, a new animation design tool developed
                      by Epic Games, brings us closer to the creation of
                      characters that can fool us into believing that they are
                      real. The tool allows artists to easily create and animate
                      extraordinarily realistic computer graphics characters.
                      MetaHuman Creator uses AI techniques in several steps of
                      this creation process. Once MetaHuman characters are
                      created, they go “downstream” to the films, games or other
                      applications for which they were intended. They are most
                      often “non-player characters” (NPCs), the equivalent of
                      extras in a film. But as the AI programs that animate
                      these characters become more sophisticated, the NPCs can
                      demonstrate a wide range of believable interactions with
                      other characters and their environment.
                    </p>
                    <p>
                      The idea of creating a synthetic human goes back to
                      antiquity—for example, Pygmalion in Ovid’s
                      <em>Metamorphoses</em>—and is a rich and persistent trope
                      in the world of artificial intelligence. From
                      <em>2001: A Space Odyssey</em>’s HAL 9000, to the orcs in
                      <em>Lord of the Rings</em>, and the fluid bodies of Scott
                      Eaton’s figure studies, we strive to bring the appearance
                      of sentience to the machines we make.
                    </p>
                    <p>
                      The MetaHuman Creator editor is designed for fast creation
                      and editing of highly realistic human synthetic
                      characters. These videos offer a sample of the various
                      editing modes available. New characters can be created and
                      altered by blending pre-existing characters; facial and
                      body features can be sculpted with a cursor; and specific
                      details such as skin tone, texture and eye colour can be
                      controlled with a high degree of precision.
                    </p>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="20. Emotion Recognition" data-footer-section-title="20 Objects of Wonder" id="20-objects-20-emotion-recognition">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="emotions1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\20-emotion-recognition1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="emotions2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\20-emotion-recognition3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-20-objects-20-emotion-recognition">
                    20. Emotion Recognition
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2021</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Face recognition software is among the most controversial
                      applications of artificial intelligence. Fundamental
                      questions regarding bias, racial profiling, privacy, civil
                      liberties and accuracy form the core complaints. But
                      facial recognition is also one of the most ubiquitous
                      forms of AI. If you’ve ever posted a photo or video to
                      Facebook, WeChat, Instagram or TikTok; applied for a
                      driver’s license or passport; or engaged in any activity
                      where an image of your face can be connected to your name,
                      then that image has likely become a template within a
                      facial recognition database.
                    </p>
                    <p>
                      While much of the concern around facial recognition is
                      with the terms and conditions of its construction of
                      individual identity, there are many more applications and
                      outcomes for which it can be used. Emotion recognition is
                      among the most popular, in part because of the
                      longstanding desire to understand facial expression as a
                      clear and verifiable representation of a person’s
                      emotional state. The debate around emotion and facial
                      expression has been active for centuries. Charles Darwin’s
                      treatise on
                      <em>The Expression of the Emotions in Man and Animals</em>
                      (1872) set the groundwork for a universal theory of
                      expression that was revived in the 1960s and 70s by the
                      American psychologist, Paul Ekman. Ekman proposed that
                      humans worldwide could reliably infer emotional states
                      from facial expressions, which he reduced to seven basic
                      emotions: happiness, sadness, anger, contempt, disgust,
                      fear and surprise. Not surprisingly, a growing body of
                      research quickly emerged to counter Ekman’s proposition
                      arguing that his definitions of facial expression were too
                      limited, and that a broader physiological analysis was
                      needed along with an understanding of context.
                    </p>
                    <p>
                      However, much of the emotion recognition software that is
                      produced today has its basis in Ekman’s thesis—a reductive
                      set of seven emotions and a belief in the cultural
                      universality of those expressions. This is a framework
                      that is especially amenable to computation and computer
                      vision—and is equally appealing to the magical thinking
                      that drives much of the marketing campaigns and
                      advertising schemes of contemporary life.
                    </p>
                    <br>
                    <div class="backmatter">
                      <p>
                        This interactive encounter with emotion recognition is
                        the result of a collaboration with Vancouver’s Centre
                        for Digital Media, under the direction of Larry Bafia.
                        Graduate students in this program worked as a team to
                        design, program and produce this wall. Many thanks to
                        that talented team:
                      </p>
                      <p>
                        Valentina Forte-Hernandez: Project Manager<br>
                        Courtney Clarkson: UX / UI Designer<br>
                        Julia Read: UX / UI Designer<br>
                        Vlad Ryzhov: Software Programmer<br>
                        Vlad Ryzhov contributed additional post-production
                        programming support
                      </p>
                      <p>
                        The Centre for Digital Media was founded in 2007 and is
                        a unique graduate program whose degree is imprinted with
                        the seals of its four partner institutions: University
                        of British Columbia, Emily Carr University of Art +
                        Design, Simon Fraser University and British Columbia
                        Institute of Technology.
                      </p>
                      <p>
                        The emotion recognition software used in this
                        interactive installation is produced by Visage
                        Technologies, founded in Linköping, Sweden.
                      </p>
                    </div>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-contents" data-footer-page-title="Special Projects: Pause" id="special-projects-pause">
          <section class="quire-page__header hero">
            <div class="hero-body">
              <h1 class="quire-page__header__title" id="special-projects-pause">
                Special Projects: Pause
              </h1>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container is-fullhd">
              <div class="quire-contents-list grid">
                
                
                <nav class="table-of-contents menu-list" data-outputs-include="pdf">
                  <ol class="table-of-contents-list">
                    <li class="level-1 page-item">
                      <a href="#special-projects-pause-sp-creepers">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\SP-creepers1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            Creepers
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#special-projects-pause-sp-airegan">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\SP-airegan1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            *airegan
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#special-projects-pause-sp-frid-jimenez">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\SP-frid-jimenez1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            Amber Frid-Jimenez
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#special-projects-pause-sp-bjarke-ingels">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\11-alphago2.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            Bjarke Ingels Group Vancouver House
                          </div>
                        </div>
                      </a>
                    </li>
                  </ol>
                </nav>
                <div class="content"></div>
              </div>
              
            </div>
          </section>
        </section><section class="quire-page quire-entry" data-footer-page-title="Creepers" data-footer-section-title="Special Projects: Pause" id="special-projects-pause-sp-creepers">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="creepers1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-creepers1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-special-projects-pause-sp-creepers">
                    Creepers
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2021–22</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Preference engines guide us daily as we move through the
                      world. They suggest products, services and information.
                      They give shape to our experiences, behaviours and
                      choices. The news you read, the music you listen to, the
                      clothing you buy, the video you watch, and the information
                      you seek were probably offered by a preference engine. In
                      this sense, we have all become data within a massive
                      artificial intelligence that tirelessly monitors our
                      activities with the intent of gauging our<br>
                      interest and engagement.
                    </p>
                    <p>
                      Curiously, most art galleries and museums have actively
                      avoided the type of monitoring that is required to make
                      accurate predictions around visitor preference. Some
                      galleries monitor attendance and ticket sales—occasionally
                      taking user surveys or consulting with focus groups—but
                      artificial intelligence provides us with some new options.
                    </p>
                    <p>
                      We commissioned <em>Creepers</em> as a tool to track
                      visitor movement and attention in this exhibition space.
                      As visitors enter this portion of the exhibition, they are
                      tracked by human detection software that assigns them an
                      individual number and colour; and their movement is
                      tracked and displayed on a nearby monitor with a coloured
                      line that marks their path in real time. When they stop to
                      look at an object or image, a slowly growing concentric
                      circle marks the place and duration of their pause. With
                      this simple tool, we can easily gauge visitor behaviour:
                      do people look at everything in the room or only a few
                      select things? What’s the path of their movement? Do they
                      pause to look at an artwork or read a label? How long do
                      they stop? Which works attract the most attention? Which
                      attract the least?
                    </p>
                    <br>
                    <div class="backmatter">
                      <p>
                        This interactive encounter with visitor tracking is the
                        result of a collaboration with Vancouver’s Centre for
                        Digital Media, under the direction of Larry Bafia.
                        Graduate students in this program worked as a team to
                        design, program and produce this wall.
                      </p>
                      <p>Many thanks to that talented team:</p>
                      <ul>
                        <li>Mary Wilson: Project Manager, UI/UX Designer</li>
                        <li>Shruti Sharma: Project Manager, UX Designer</li>
                        <li>Yuri Wu – Artist / UX Designer</li>
                        <li>Cindy Shi – Software Programmer</li>
                        <li>Min Kyu Choi – Software Programme</li>
                        <li>Jason Elliot – Faculty Advisor</li>
                      </ul>
                      <p>
                        Cindy Shi contributed additional post-production
                        programming support.
                      </p>
                      <p>
                        The Centre for Digital Media was founded in 2007 and is
                        a unique graduate program whose degree is imprinted with
                        the seals of its four partner institutions: University
                        of British Columbia, Emily Carr University of Art +
                        Design, Simon Fraser University and British Columbia
                        Institute of Technology.
                      </p>
                    </div>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="*airegan" data-footer-section-title="Special Projects: Pause" id="special-projects-pause-sp-airegan">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="airegan1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-airegan1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="airegan2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-airegan2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="airegan3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-airegan3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="airegan4" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-airegan4.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-special-projects-pause-sp-airegan">
                    *airegan
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2021–22</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      The design group at *airegan produces a complex working
                      model that might best be described as having some
                      similarity to the latent space of a neural network—which
                      is to say, a multidimensional space that we cannot
                      interpret directly, but which encodes a meaningful
                      internal representation of externally observed events.
                    </p>
                    <p>
                      Evoking Marcel Duchamp, the artists and designers at
                      *airegan see the sneaker as a readymade: "…the
                      meticulous assembly of bootlegs, one of a kind sneakers
                      and mass market brands—including couture and hype brands.
                      The series further references qualities of readymade
                      sneakers, and their form factors reflect in the final
                      works by reapproaching, redefining and reappropriating the
                      readymade.
                    </p>
                    <p>
                      Using the tools of generative adversarial networks (GANs),
                      *airegan offers the unlikely possibility of a new kind of
                      readymade, as well as an unexpected reconfiguration of the
                      terms of creativity in the age of artificial intelligence.
                    </p>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="Amber Frid-Jimenez" data-footer-section-title="Special Projects: Pause" id="special-projects-pause-sp-frid-jimenez">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="frid1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-frid-jimenez1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="frid2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-frid-jimenez2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="frid3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-frid-jimenez3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-special-projects-pause-sp-frid-jimenez">
                    Amber Frid-Jimenez
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2018</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Amber Frid-Jimenez is a Vancouver-based interdisciplinary
                      artist with a background in computational design and the
                      creation of experimental computer programs, platforms and
                      applications.
                    </p>
                    <p>
                      <em>Après Ballet mécanique</em> (2018) is a video created
                      by Frid-Jimenez that uses artificial intelligence to
                      generate a new configuration of Fernand Léger’s
                      experimental film <em>Ballet mécanique</em> (1924). Ballet
                      mécanique is an important and influential work within
                      European modernist art of the early 20th century. Using
                      aggressively experimental film techniques and subject
                      matter, Léger created a new kind of image.
                    </p>
                    <p>
                      To produce her work, <em>Après Ballet mécanique</em>,
                      Frid-Jimenez takes a similarly experimental approach,
                      using Léger’s film to construct a learning set—the dataset
                      of images used to “train” an artificial neural network—and
                      then reconstruct a new version of the film from within the
                      multidimensional image space produced by the neural
                      network. The result is a very different film, reflecting a
                      sense of time, space and form that is firmly rooted in the
                      age of artificial intelligence.
                    </p>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="Bjarke Ingels Group Vancouver House" data-footer-section-title="Special Projects: Pause" id="special-projects-pause-sp-bjarke-ingels">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="bjarke1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\11-alphago2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-special-projects-pause-sp-bjarke-ingels">
                    Bjarke Ingels Group Vancouver House
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2020</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Responding to a complex building site, the Bjarke Ingels
                      Group utilized the power of parametric design to produce a
                      Vancouver landmark. Vancouver House was designed in
                      response to a number of unique parameters that resulted
                      from its constrained site, an option for expanded
                      airspace, and a commitment to public space at the foot of
                      the tower.
                    </p>
                    <p>
                      In an extraordinary feat of design, the building structure
                      emerges from a triangular floorplate that twists and
                      expands slowly as it rises, achieving a rectangular form
                      near the top of its 59 storeys.
                    </p>
                    <p>
                      The building’s design relies heavily on the capacity of
                      computational design to manage the variety and incremental
                      shifting of form as the building rises and rotates.
                    </p>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-contents" data-footer-page-title="Special Projects: Artist Projects" id="special-projects-artists-projects">
          <section class="quire-page__header hero">
            <div class="hero-body">
              <h1 class="quire-page__header__title" id="special-projects-artist-projects">
                Special Projects: Artist Projects
              </h1>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container is-fullhd">
              <div class="quire-contents-list grid">
                
                
                <nav class="table-of-contents menu-list" data-outputs-include="pdf">
                  <ol class="table-of-contents-list">
                    <li class="level-1 page-item">
                      <a href="#special-projects-artists-projects-sp-pennefather">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\SP-pennefather1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            Patrick Pennefather
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#special-projects-artists-projects-sp-chung">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\SP-chung1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            Sougwen Chung
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#special-projects-artists-projects-sp-eaton">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\SP-eaton1.jpg" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            Scott Eaton
                          </div>
                        </div>
                      </a>
                    </li>
                    <li class="level-1 page-item">
                      <a href="#special-projects-artists-projects-sp-zombie">
                        <div class="card image">
                          <div class="card-image">
                            <figure class="image">
                              <img src="\_assets\images\install\SP-zombie1.JPEG" alt="">
                            </figure>
                          </div>

                          <div class="card-content">
                            The Zombie Formalist
                          </div>
                        </div>
                      </a>
                    </li>
                  </ol>
                </nav>
                <div class="content"></div>
              </div>
              
            </div>
          </section>
        </section><section class="quire-page quire-entry" data-footer-page-title="Patrick Pennefather" data-footer-section-title="Special Projects: Artist Projects" id="special-projects-artists-projects-sp-pennefather">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="pennefather1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-pennefather1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="pennefather2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-pennefather3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="pennefather3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-pennefather5.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-special-projects-artists-projects-sp-pennefather">
                    Patrick Pennefather
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2022</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>What does AI sound like?</p>
                    <p>
                      AI permeates our world, but is the sound of AI something
                      specific, or is it the subtle reshaping of the soundscape
                      that surrounds our daily lives? <em>Sounds Like AI</em> is
                      a long-form soundscape that integrates sounds common to
                      the Gallery’s exhibition space (for example, the constant
                      hum of the escalator), sounds that we typically associate
                      with computers and AI (for example, sound effects from
                      films), and random snippets of speech that resemble the
                      talkin AI agents we encounter everyday (for example,
                      Alexa, Siri and “Hey Google.”)
                    </p>
                    <p>
                      Patrick Pennefather describes the work as “a sonic resting
                      point amidst the often disorienting and chaotic sounds we
                      experience in public spaces.”
                    </p>
                    <p>
                      The rotunda soundscape, <em>Are you Talking to Me?</em>,
                      interactively tracks visitors using a motion tracking
                      system and targets individual visitors with specialized
                      speakers that have an extremely tight focus. The selection
                      of what audio is played is determined partly by where in
                      the rotunda that audio is being projected by the tightly
                      focused speakers, and in that sense audio content is also
                      responsive to each visitor’s movements. The result is a
                      constantly changing and never-repeating sound experience
                      that is shaped by the movement of the visitors who
                      experience it.
                    </p>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="Sougwen Chung" data-footer-section-title="Special Projects: Artist Projects" id="special-projects-artists-projects-sp-chung">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="chung1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-chung1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="chung2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-chung2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="chung3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-chung4.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="chung4" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-chung14.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="chung5" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-chung18.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="chung6" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-chung20.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="chung7" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-chung21.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-special-projects-artists-projects-sp-chung">
                    Sougwen Chung
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2017–22</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Sougwen Chung is a Chinese-Canadian artist and researcher
                      currently based in London, England. Over the past decade,
                      she has engaged in research that links humans and machines
                      in an intricate and compelling collaboration. More
                      recently she has extended that collaboration to include a
                      broader range of ecologies—seeking to produce new modes of
                      creativity that blur the conventional boundaries between
                      human and non-human knowledge.
                    </p>
                    <p>
                      Her installation for this exhibition offers a selected
                      introduction to some of the key bodies of work she has
                      produced in the last five years. With an extensive
                      background in computational science and art, Chung
                      utilizes machine learning, computer vision, neural
                      networks and advanced robotics in a speculative practice
                      that finds meaning in flow, change, entanglement and
                      indeterminacy.
                    </p>
                    <p>
                      Performance is a critical element of Chung’s
                      practice—where human and machine meet in their most
                      intimate and inextricable engagement. In a recent text
                      Chung called for a recognition of “machine intelligence,
                      flux and unknown destinations. Machine co-creation—not a
                      replication or automation of human endeavour but a
                      mechanism (mysticism) developed toward the transformation
                      of the human subject. A form of mysticism.”
                    </p>
                    <section id="section-d-o-u-g-2-dataset-sample" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>D.O.U.G.2 Dataset Sample</h2>
                      <p>
                        The artist collected and scanned samples of her previous
                        drawings and sketches—100 are shown in the exhibition—to
                        produce a memory bank for D.O.U.G._2. She has since
                        continued to add drawings focusing on gesture and colour
                        palette. Together, they constitute a collective memory
                        that the robotic arm could draw on when creating these
                        two works.
                      </p>
                    </section>
                    
                    <section id="section-d-o-u-g-l-a-s" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>D.O.U.G.L.A.S.</h2>
                      <p>
                        The drawing robots on the centre platform collaborated
                        with the artist in the production of the painting you
                        see there. They are part of a “family” or “swarm” of
                        robots that work collectively—with Chung and with each
                        other—to produce gestures that reflect their
                        interactions in a shared space. In part, the robots’
                        movements are based on data gathered by surveillance
                        cameras in public spaces. The data is extracted through
                        algorithms that capture optical flow,<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>
                        which can be defined as the pattern of motion of objects
                        in a visual scene—velocity, direction, density and dwell
                        time. Two paintings from this series—<em>Dwell Study</em>
                        (2018) and <em>Direction Study</em> (2018)—hang nearby.
                      </p>
                      <p>
                        Optical flow is a critical field of study in computer
                        vision and machine movement, and Chung’s project emerged
                        in part from the Experiments in Arts and Technology
                        (E.A.T.) residency at the legendary Bell Labs. The
                        E.A.T. collective first paired engineers from Bell Labs
                        with artists in 1966, and this visionary partnership
                        continues to support collaborative artistic projects
                        that engage emergent technologies.
                      </p>
                      <div class="backmatter"></div>
                      <section class="footnotes">
                        <ol class="footnotes-list">
                          <li id="fn1" class="footnote-item">
                            <p>
                              Optical flow is a technique used to describe image
                              motion. It is usually applied to a series of
                              images that have a small time step between them,
                              for example, video frames. Optical flow calculates
                              a velocity for points within the images, and
                              provides an estimation of where points could be in
                              the next image sequence.
                              <a href="#fnref1" class="footnote-backref">↩︎</a>
                            </p>
                          </li>
                        </ol>
                      </section>
                    </section>
                    
                    <section id="section-flora-rearing-agricultural-network-f-r-a-n" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Flora Rearing Agricultural Network (F.R.A.N.)</h2>
                      <p>
                        In this video work, Sougwen Chung establishes the
                        framework for an ongoing project that is connected to
                        nature through a process linked to the artist’s
                        biorhythms. Here, Chung explores new modes of relation
                        between humans, plants and machines.
                      </p>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="Scott Eaton" data-footer-section-title="Special Projects: Artist Projects" id="special-projects-artists-projects-sp-eaton">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="eaton1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-eaton1.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="eaton2" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-eaton2.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="eaton3" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-eaton3.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="eaton4" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-eaton5.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="eaton5" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-eaton6.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="eaton6" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-eaton7.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>

              <figure id="eaton7" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-eaton9.jpg" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-special-projects-artists-projects-sp-eaton">
                    Scott Eaton
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2018–22</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      Scott Eaton is an American-born artist based in London. As
                      a long-time student of the human figure, Eaton has built a
                      commercial database of human figures—both still and in
                      motion—and has produced an extensive body of photographic
                      and hand-drawn figurative work. He teaches human anatomy
                      and figure drawing for artists, and consults for a variety
                      of video game and animation production houses.
                    </p>
                    <p>
                      The work in this room addresses one of the oldest subjects
                      of art: the human body. But the tools used for this
                      exploration employ some of the most recent and
                      sophisticated advances in artificial intelligence: neural
                      networks.
                    </p>
                    <p>
                      The “Bodies” neural network that produced the human bodies
                      displayed here was designed and trained by the artist with
                      over 25,000 photographs of carefully lit and staged human
                      figures. As neural networks can only recognize and produce
                      the types of images on which they were trained, the
                      “Bodies” network can only “see” the human form.
                    </p>
                    <p>
                      Consequently, in its interactions with Eaton, the network
                      can only produce the human body. The network responds to
                      lines drawn by Eaton by attempting to give a fleshy
                      surface and lighting to that form. No matter what image
                      Eaton feeds into the network, the digital output will be a
                      human body that is shaped by the parameters of the input
                      image. Draw a line, get back a body part. Capture fluids
                      in motion, get back fluid bodies in motion.
                    </p>
                    <p>
                      <em>Entangled II</em> was produced using high-speed video
                      of fluid movement shot with macro lenses, then processed
                      through a custom pix2pixHD model (a type of neural
                      network) trained on the artist’s “Bodies” dataset of more
                      than 25,000 images of the human body in motion.
                    </p>
                    <section id="section-humanity-fall-of-the-damned" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Humanity (Fall of the Damned)</h2>
                      <p>
                        To create this work, a large composition, hand-drawn by
                        the artist, was processed by a custom neural network
                        that was trained on the artist’s “Bodies” dataset. Eaton
                        was inspired by the many large-scale depictions of the
                        Last Judgment that were produced during the Renaissance.
                        The computer processing required to render the complex
                        volumes and shading for each body in such a large-scale
                        and highly detailed image posed a significant technical
                        challenge. To resolve this problem, Eaton produced the
                        image in smaller, tiled pieces, which he then
                        reassembled for printing.
                      </p>
                    </section>
                    
                    <section id="section-caffeinated-diversions" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Caffeinated Diversions</h2>
                      <p>
                        Sophisticated neural networks are complex and can
                        produce surprising results. Extensive experimentation is
                        necessary to tune the design and training of a neural
                        network, and to discover what it can do.
                        <em>Caffeinated Diversions</em> presents a selection of
                        Scott Eaton’s daily exercises to discover what he can
                        produce with the AI neural networks he has trained.
                      </p>
                      <p>
                        Each starts with a sketch—a simple line drawing. Then,
                        the neural network takes over as it tries to process the
                        sketch through the patterns on which it was trained; in
                        this case, thousands of photographs of human bodies in
                        various positions taken by the artist. As Eaton
                        describes it: “in some ways the neural network was
                        training me in reverse to draw differently, to get it to
                        do the right thing.”
                      </p>
                    </section>
                    
                    <section id="section-figures-rectangles-and-reflection" class="accordion-section" data-outputs-include="epub,pdf">
                      <h2>Figures, Rectangles and Reflection</h2>
                      <p>
                        In this new work, the initial output is produced by a
                        StyleGan3 generator trained on the artist’s “Bodies”
                        dataset, and then processed by a custom Pix2PixHD model
                        which has been trained on simple geometric shapes. The
                        final output is rendered in Octane Render.
                      </p>
                    </section>
                    
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page quire-entry" data-footer-page-title="The Zombie Formalist" data-footer-section-title="Special Projects: Artist Projects" id="special-projects-artists-projects-sp-zombie">
          <div class="side-by-side">
            

            <div class="quire-entry__image-wrap" data-outputs-include="epub,pdf">
              <figure id="zombie1" class="q-figure q-figure--image">
                
                
                <img alt="." class="q-figure__image" src="\_assets\images\install\SP-zombie1.JPEG" data-outputs-include="epub,pdf">
                <figcaption class="q-figure__caption" data-outputs-include="epub,pdf">
                  <span class="q-figure__caption-content">.</span>
                  <span class="q-figure__credit">Photo: Ian Lefebvre and Jessica Jacobson, Vancouver Art
                    Gallery</span>
                </figcaption>
              </figure>
            </div>

            <div class="quire-entry__content">
              <header class="quire-entry__header">
                <div class="container">
                  <h1 class="quire-page__header__title" id="page-header-special-projects-artists-projects-sp-zombie">
                    The Zombie Formalist
                  </h1>
                  <div class="quire-page__header__contributor"></div>
                </div>
              </header>

              <section class="quire-entry__tombstone">
                <div class="container">
                  <table class="table is-fullwidth">
                    <tbody>
                      <tr>
                        <td>Year</td>
                        <td>2022</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  <div class="content">
                    <p>
                      The Zombie Formalist is the first product of its kind.
                    </p>
                    <p>
                      The Zombie Formalist is a self-contained generative
                      lightbox that uses an embedded Artificial Intelligence
                      (AI) system to learn your aesthetic preferences. It has a
                      limitless capacity to create new geometric abstract
                      compositions tailored specifically for you.
                    </p>
                    <p>
                      The Zombie Formalist will show you more of what you want
                      to see. It pays attention to artworks that pique your
                      interest, and then creates new compositions with similar
                      characteristics. The Zombie Formalist is an artist itself:
                      based on your input, it creates unique works in real time
                      just for you.
                    </p>
                    <p>
                      The Zombie Formalist can upload artworks to Twitter where
                      the engagement of your followers will further determine
                      its aesthetic decision making—producing compositions that
                      your friends will appreciate.
                    </p>
                    <p>
                      By clicking here, you can join over 1000 fans who engage
                      with the Zombie Formalist on Twitter. Follow the Zombie
                      Formalist and your likes and retweets will teach the AI
                      system what is aesthetically pleasing to you while
                      improving its future compositions!
                    </p>
                    <p>
                      In conjunction with
                      <em>The Imitation Game: Visual Culture in the Age of
                        Artificial Intelligence</em>, the Zombie Formalist has created a series of exclusive,
                      limited edition products for sale. These items are based
                      on the Gallery Store’s bestselling merchandise and feature
                      digital compositions that rated highly on Twitter.
                    </p>
                  </div>
                </div>
              </section>

              <section class="section quire-page__content">
                <div class="container">
                  
                </div>
              </section>
            </div>
          </div>
        </section><section class="quire-page" data-footer-page-title="AI Glossary" id="ai-glossary">
          <section class="quire-page__header hero">
            <div class="hero-body">
              <h1 class="quire-page__header__title" id="ai-glossary">
                AI Glossary
              </h1>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container">
              <div class="content">
                <p><strong>A</strong></p>
                <dl>
                  <dt>Algorithm</dt>
                  <dd>
                    An algorithm is a set of instructions or a recipe for
                    solving a problem or accomplishing a task.
                  </dd>
                  <dt>Algorithmic Bias</dt>
                  <dd>
                    A phenomenon that occurs when an AI algorithm produces
                    results that are systemically prejudiced due to erroneous
                    assumptions in the machine learning process.
                  </dd>
                  <dt>Algorithmic Design or Computational Design</dt>
                  <dd>
                    Algorithmic design or computational design is defined as the
                    ways in which design meaning, intentions and knowledge are
                    constructed through computational thinking, representing,
                    sensing and making.
                  </dd>
                  <dt>Artificial Intelligence</dt>
                  <dd>
                    Artificial Intelligence (AI) is the ability of a digital
                    computer or computer-controlled robot to perform tasks
                    commonly associated with intelligent beings.
                  </dd>
                </dl>
                <p><strong>B</strong></p>
                <dl>
                  <dt>Biometric Surveillance Technologies</dt>
                  <dd>
                    Biometric technology is the use of human characteristics to
                    identify individuals and is a form of surveillance. The word
                    biometric is derived from the Greek words bio (which means
                    life) and metric (which means to measure). Common forms of
                    biometrics are fingerprint scanners and face identification.
                  </dd>
                  <dt>Boids</dt>
                  <dd>
                    Boids is an artificial life program, developed by Craig
                    Reynolds in 1986, which simulates the flocking behaviour of
                    birds.
                  </dd>
                </dl>
                <p><strong>C</strong></p>
                <dl>
                  <dt>Co-naturality</dt>
                  <dd>
                    Co-naturality refers to a sympathy that exists been two
                    objects that share the same nature.
                  </dd>
                  <dt>Computer Interface</dt>
                  <dd>
                    The human-machine interface, also called user interface or
                    human-computer interface, is the means by which humans and
                    computers communicate with each other. The human-machine
                    interface includes the hardware and software that is used to
                    translate user (i.e. human) input into commands and to
                    present results to the user.
                  </dd>
                  <dt>Computer Vision</dt>
                  <dd>
                    Computer vision is a field of artificial intelligence that
                    enables computers and systems to derive meaningful
                    information from digital images, videos and other visual
                    inputs.
                  </dd>
                  <dt>Cybernetics</dt>
                  <dd>
                    Norbert Wiener introduced the term “cybernetics” in 1948 and
                    described it as “the science of control and communications
                    in the animal and machine.”
                  </dd>
                </dl>
                <p><strong>D</strong></p>
                <dl>
                  <dt>Dataset</dt>
                  <dd>
                    A dataset is a collection of data that can be used to train
                    an algorithm with the goal of finding predictable patterns
                    inside the whole dataset.
                  </dd>
                  <dt>Deep Learning</dt>
                  <dd>
                    Deep Learning is a subset of machine learning, which is
                    essentially a neural network with three or more layers.
                  </dd>
                  <dt>Deepfakes</dt>
                  <dd>
                    Deepfakes (a portmanteau of "deep learning" and
                    "fake") are synthetic media in which a person in
                    an existing image or video is replaced with someone else’s
                    likeness.
                  </dd>
                </dl>
                <p><strong>F</strong></p>
                <dl>
                  <dt>Facial Recognition System</dt>
                  <dd>
                    A facial recognition system is a technology capable of
                    matching a human face from a digital image or a video frame
                    against a database of faces, typically employed to
                    authenticate users through ID verification services. It
                    works by pinpointing and measuring facial features from a
                    given image.
                  </dd>
                  <dt>Funicular Structure</dt>
                  <dd>
                    The funicular concept can be best described and visualized
                    with cables or chains, suspended from two points, that
                    adjust their form for any load in tension.
                  </dd>
                </dl>
                <p><strong>G</strong></p>
                <dl>
                  <dt>Game Theory</dt>
                  <dd>
                    Game theory is the study of mathematical models of strategic
                    interactions among rational agents.
                  </dd>
                  <dt>Generative Adversarial Network</dt>
                  <dd>
                    A generative adversarial network (GAN) is a class of machine
                    learning frameworks in which two neural networks train each
                    other by competing in a zero-sum game, where one agent’s
                    gain is another agent’s loss.
                  </dd>
                </dl>
                <p><strong>L</strong></p>
                <dl>
                  <dt>Lissajous Curve</dt>
                  <dd>
                    A Lissajous curve is the graph of a system of parametric
                    equations which describe complex harmonic motion.
                  </dd>
                </dl>
                <p><strong>M</strong></p>
                <dl>
                  <dt>Machine Learning</dt>
                  <dd>
                    Machine learning is an application of AI that enables
                    systems to learn and improve from experience without being
                    explicitly programmed.
                  </dd>
                  <dt>The Mechanical Turk</dt>
                  <dd>
                    The Turk, also known as the Mechanical Turk or Automaton
                    Chess Player, was a fake chess-playing machine constructed
                    in the late 18th century.
                  </dd>
                </dl>
                <p><strong>N</strong></p>
                <dl>
                  <dt>Neural Network</dt>
                  <dd>
                    Neural networks are computing systems with interconnected
                    nodes that work much like neurons in the human brain. Using
                    algorithms, they can recognize hidden patterns and
                    correlations in raw data, cluster and classify it, and–over
                    time–continuously learn and improve.
                  </dd>
                </dl>
                <p><strong>O</strong></p>
                <dl>
                  <dt>Optical Flow</dt>
                  <dd>
                    Optical flow is a technique used to describe image motion.
                    It is usually applied to a series of images that have a
                    small time step between them, for example, video frames.
                    Optical flow calculates a velocity for points within the
                    images, and provides an estimation of where points could be
                    in the next image sequence.
                  </dd>
                </dl>
                <p><strong>P</strong></p>
                <dl>
                  <dt>Parametric Design</dt>
                  <dd>
                    Parametric design is understood as a process where a
                    description of a problem is created using variables. By
                    changing these variables a range of alternative solutions
                    can be created, then based on some criteria a final solution
                    selected.
                  </dd>
                  <dt>Preference Engine</dt>
                  <dd>
                    A preference engine, or a recommender system, is a subclass
                    of information filtering systems that seeks to predict the
                    "rating" or "preference" a user would
                    give to an item.
                  </dd>
                  <dt>Prompt Engineering</dt>
                  <dd>
                    Prompt engineering or prompt programming is an interesting
                    way to interact with GPT-3 neural network systems. It
                    basically involves creating clever text-based scripts that
                    make GPT-3 perform the tasks you desire.
                  </dd>
                </dl>
                <p><strong>R</strong></p>
                <dl>
                  <dt>Reinforcement Learning</dt>
                  <dd>
                    Reinforcement learning is an area of machine learning
                    concerned with how intelligent agents ought to take actions
                    in an environment in order to maximize the notion of
                    cumulative reward. Reinforcement learning is one of three
                    basic machine learning paradigms, alongside supervised
                    learning and unsupervised learning.
                  </dd>
                </dl>
                <p><strong>S</strong></p>
                <dl>
                  <dt>System Dynamics</dt>
                  <dd>
                    System dynamics is an approach to understanding the
                    nonlinear behaviour of complex systems over time using
                    stocks, flows, internal feedback loops, table functions and
                    time delays.
                  </dd>
                </dl>
                <p><strong>T</strong></p>
                <dl>
                  <dt>Turing Test</dt>
                  <dd>
                    The Turing test, originally called “the imitation game” by
                    Alan Turing in 1950, is a test of a machine's ability to
                    exhibit intelligent behaviour equivalent to, or
                    indistinguishable from, that of a human.
                  </dd>
                </dl>
                <p><strong>W</strong></p>
                <dl>
                  <dt>WordNet</dt>
                  <dd>
                    WordNet is the name used for lexical databases derived from
                    the original Princeton WordNet; they group words into
                    synonym sets and interlink them using lexical and
                    conceptual-semantic relations. These databases are used for
                    computational linguistics and natural language processing.
                  </dd>
                </dl>
              </div>
              
            </div>
          </section>
        </section><section class="quire-page" data-footer-page-title="Contributors" id="contributors">
          <section class="quire-page__header hero">
            <div class="hero-body">
              <h1 class="quire-page__header__title" id="contributors">
                Contributors
              </h1>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container">
              <div class="content">
                <ul class="quire-contributors-list bio align-left">
                  <li class="quire-contributor" id="glenn-entis">
                    <div class="title is-5">
                      <span class="quire-contributor__name">Glenn Entis</span>
                    </div>
                    <div class="media">
                      <div class="quire-contributor__details media-content">
                        <ul></ul>
                      </div>
                    </div>
                  </li>
                  <li class="quire-contributor" id="bruce-grenville">
                    <div class="title is-5">
                      <span class="quire-contributor__name">Bruce Grenville</span>
                    </div>
                    <div class="media">
                      <div class="quire-contributor__details media-content">
                        <div class="quire-contributor__bio">
                          Bruce Grenville was the Senior Curator at the
                          Vancouver Art Gallery from 1997 to 2022. During that
                          time he organized many thematic group exhibitions
                          including
                          <em>The Imitation Game: Visual Culture in the Age of
                            Artificial Intelligence</em>
                          (2022); <em>Cabin Fever</em> (2018), an historical
                          survey of the cabin typology in North American
                          architecture and visual culture;
                          <em>MashUp: The Birth of Modern Culture</em> (2016),
                          an exhibition and publication focused on the history
                          of mashup culture from 1912 to the present;
                          <em>Massive Change: The Future of Global Design</em>
                          (2004), a survey of contemporary design, conceived and
                          presented in collaboration with Bruce Mau Design and
                          the Institute Without Boundaries; and
                          <em>Home and Away: Crossing Cultures on the Pacific
                            Rim</em>
                          (2003), a look at the work of six artists who share a
                          history of emigration and diaspora on the Pacific Rim.
                          He also organized numerous solo exhibitions for
                          artists including Carol Sawyer, Janet Cardiff and
                          George Bures Miller, Michael Lin, Fiona Tan, Stan
                          Douglas, Franz West, Wang Du, Gathie Falk, Dominique
                          Blain, Komar and Melamid, Arnaud Maggs, Christos
                          Dikeakos, Ruth Cuthand, Mary Scott and Jack Goldstein.
                        </div>
                        <ul></ul>
                      </div>
                    </div>
                  </li>
                </ul>
              </div>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container">
              
            </div>
          </section>
        </section><section class="quire-page" data-footer-page-title="Colophon" id="colophon">
          <section class="quire-page__header hero">
            <div class="hero-body">
              <h1 class="quire-page__header__title" id="colophon">Colophon</h1>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container">
              <div class="content">
                <p>
                  Published in conjunction with the exhibition
                  <em>The Imitation Game: Visual Culture in the Age of Artificial
                    Intelligence</em>, organized by the Vancouver Art Gallery, curated by Bruce
                  Grenville, Senior Curator, and Glenn Entis, Guest Curator, and
                  presented from March 5 to October 23, 2022.<br>
                  <br>
                </p>
                <p>
                  Editor:<br>
                  Copyeditor and production coordinator:<br>
                  Design:<br>
                  Photography and Digital Image Preparation:
                </p>
                <br>
                <p>
                  This publication was created using Quire<sup>TM</sup>, a
                  multiplatform publishing tool created by the J. Paul Getty
                  Trust
                </p>
                <p>© 2023 Vancouver Art Gallery</p>
                <p>ISBN 978-1-927656-55-6</p>
                <p>
                  All rights reserved. No part of this book may be reproduced,
                  stored in a retrieval system or transmitted, in any form or by
                  any means, without the prior written consent of the publisher.
                </p>
                <br>
                <br>
                <p><strong>Publication Support:</strong></p>
                <p>
                  Visionary Partner for Scholarship and Publications:<br>
                  The Richardson Family
                </p>
                <p><strong>Exhibition Support:</strong></p>
                <p>
                  Generously supported by:<br>
                  Jane Irwin and Ross Hill<br>
                  The Poseley Family<br>
                  Rick Erickson and Donna Partridge
                </p>
                <p>
                  Supporting Sponsor:<br>
                  <img src="_assets/images/nicola.jpg" alt="Nicola Wealth">
                </p>
                <p>
                  AI Youth Programs Sponsor:<br>
                  The Dr. Michael Smith Science Fair Endowment
                </p>
                <p>
                  Additional support from:<br>
                  The S.M. Blair Family Foundation<br>
                  Traction on Demand
                </p>
                <p>
                  The Vancouver Art Gallery is a not-for-profit organization
                  supported by its members, individual donors, corporate
                  funders, foundations, the City of Vancouver, the Province of
                  British Columbia through the British Columbia Arts Council,
                  and the Canada Council for the Arts.
                </p>
                <br>
                <p>
                  <img src="_assets/images/vaglogo-colour.jpg" alt="Vancouver Art Gallery Logo">
                </p>
                <p>
                  Vancouver Art Gallery<br>
                  750 Hornby Street, Vancouver, BC, V6Z 2H7<br>
                  <a href="#https-www-vanartgallery-bc-ca" target="_blank">vanartgallery.bc.ca</a>
                </p>
                <br>
                The Vancouver Art Gallery respectfully acknowledges its location
                on the traditional, ancestral and unceded territories of the
                xʷməθkʷəy̓əm (Musqueam) Sḵwx̱wú7mesh (Squamish) and səlilwətaɬ
                (Tsleil-Waututh) peoples, and honours the Indigenous stewards of
                the land whose rich cultures are fundamental to artistic life in
                our province and the work of the Gallery.
              </div>
            </div>
          </section>

          <section class="section quire-page__content">
            <div class="container">
              
            </div>
          </section>
        </section></body></html>